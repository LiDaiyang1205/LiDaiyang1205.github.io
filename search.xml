<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[ORB_SLAM2 程序解读（1）]]></title>
    <url>%2F2019%2F09%2F10%2FORB_SLAM2%20%E7%A8%8B%E5%BA%8F%E8%A7%A3%E8%AF%BB%EF%BC%881%EF%BC%89%2F</url>
    <content type="text"><![CDATA[0 概述ORB-SLAM是由Raul Mur-Artal，J. M. M. Montiel和Juan D. Tardos于2015年发表在IEEE Transactions on Robotics。代码主页网址为：https://github.com/raulmur/ORB_SLAM2 。 我之所以选择ORB_SLAM2，是因为之前在研究回环检测，回环检测涉及到特征点的采集和处理，ORB就是特征点最常用的采集方法。为了实现ORB_SLAM2 的使用，我从安装依赖项到运行测试都写了完整的文档。实现ORBSLAM2的运行后，我发现这个包建图没问题，但是没有保存地图和加载地图的功能，于是又通过看博客改源码，实现了地图保存和地图加载。之前都是看着别人的博客改，自己对这个包一知半解，所以这里系统学习一下这个库。 ORB-SLAM是一个基于特征点的实时单目SLAM系统，在大规模的、小规模的、室内室外的环境都可以运行。该系统对剧烈运动也很鲁棒，支持宽基线的闭环检测和重定位，包括全自动初始化。该系统包含了所有SLAM系统共有的模块：跟踪（Tracking）、建图（Mapping）、重定位（Relocalization）、回环检测（Loop closing）。由于ORB-SLAM系统是基于特征点的SLAM系统，故其能够实时计算出相机的轨线，并生成场景的稀疏三维重建结果。 贡献： 1 系统架构ORB-SLAM其中的关键点如下图所示： ORB-SLAM主要分为三个线程进行，分别是Tracking、LocalMapping和LoopClosing。ORB-SLAM2的工程非常清晰漂亮，三个线程分别存放在对应的三个文件中，分别是Tracking.cpp、LocalMapping.cpp和LoopClosing.cpp文件中，很容易找到。 （1）跟踪（Tracking） 这一部分主要工作是从图像中提取ORB特征，根据上一帧进行姿态估计，或者进行通过全局重定位初始化位姿，然后跟踪已经重建的局部地图，优化位姿，再根据一些规则确定新的关键帧。 （2）建图（LocalMapping） 这一部分主要完成局部地图构建。包括对关键帧的插入，验证最近生成的地图点并进行筛选，然后生成新的地图点，使用局部光束平差调整（Local BA），最后再对插入的关键帧进行筛选，去除多余的关键帧。 （3）闭环检测（LoopClosing） 这一部分主要分为两个过程，分别是闭环探测和闭环校正。闭环检测先使用WOB进行探测，然后通过Sim3算法计算相似变换。闭环校正，主要是闭环融合和Essential Graph的图优化。 2 代码结构ORB-SLAM2代码写的很整洁。打开ORB-SLAM2的文件夹，你会看到以下文件夹： Examples文件夹：存放的分别是基于单目、双目、RGBD的实例程序 include文件夹：存放的是头文件，ORB-SLAM2可以被当作一个库来使用，很多函数都可以直接调用 src文件夹：存放的是和include对应的源文件，要讲的代码在该文件夹下 Thirdparty文件夹：存放的是用到的第三方库，优化库g2o在该文件夹下 Vocabulary文件夹：存放的是回环检测中BoW用到的视觉词典名为ORBvoc.txt build.sh:配置文件 其中变量命名规则： “p”表示指针数据类型；”n”表示int类型；“b”表示bool类型；”s”表示set类型； ”v”表示vevtor数据类型；“l”表示list数据类型；”m”表示类成员变量 3 ros_rgbd.ccORB_SLAM的代码非常整齐，简洁，便于阅读。由于我们用的是Kinect 2，有自己的slam小车，用的是ROS实现，所以使用的是/Examples/ROS/ORB_SLAM2/src/ros_rgbd.cc这个主程序。 1 定义了图像采集的类 123456789class ImageGrabber //图像采集&#123;public: ImageGrabber(ORB_SLAM2::System* pSLAM):mpSLAM(pSLAM)&#123;&#125; void GrabRGBD(const sensor_msgs::ImageConstPtr&amp; msgRGB,const sensor_msgs::ImageConstPtr&amp; msgD); ORB_SLAM2::System* mpSLAM;&#125;; 2 定义 ImageGrabber::GrabRGBD 函数 123456789101112131415161718192021222324252627void ImageGrabber::GrabRGBD(const sensor_msgs::ImageConstPtr&amp; msgRGB,const sensor_msgs::ImageConstPtr&amp; msgD)&#123; // Copy the ros image message to cv::Mat. cv_bridge::CvImageConstPtr cv_ptrRGB; // RGB信息 try &#123; cv_ptrRGB = cv_bridge::toCvShare(msgRGB); &#125; catch (cv_bridge::Exception&amp; e) &#123; ROS_ERROR("cv_bridge exception: %s", e.what()); return; &#125; cv_bridge::CvImageConstPtr cv_ptrD; // 深度信息 try &#123; cv_ptrD = cv_bridge::toCvShare(msgD); &#125; catch (cv_bridge::Exception&amp; e) &#123; ROS_ERROR("cv_bridge exception: %s", e.what()); return; &#125; mpSLAM-&gt;TrackRGBD(cv_ptrRGB-&gt;image,cv_ptrD-&gt;image,cv_ptrRGB-&gt;header.stamp.toSec());&#125; 2 主函数 123//初始化启动rosros::init(argc, argv, "RGBD");ros::start(); 12//创建ORB_SLAM2系统对象ORB_SLAM2::System SLAM(argv[1],argv[2],ORB_SLAM2::System::RGBD,true); 12//创建ImagGrabb 对象 igbImageGrabber igb(&amp;SLAM); 123456//读取rgb和深度信息message_filters::Subscriber&lt;sensor_msgs::Image&gt; rgb_sub(nh,"/kinect2/qhd/image_color",1);message_filters::Subscriber&lt;sensor_msgs::Image&gt; depth_sub(nh,"/kinect2/qhd/image_depth_rect",1);typedef message_filters::sync_policies::ApproximateTime&lt;sensor_msgs::Image, sensor_msgs::Image&gt; sync_pol;message_filters::Synchronizer&lt;sync_pol&gt; sync(sync_pol(10),rgb_sub,depth_sub);sync.registerCallback(boost::bind(&amp;ImageGrabber::GrabRGBD,&amp;igb,_1,_2)); 12345678//slam系统操作，加载、保存、关闭 //SLAM.LoadMap("/home/zj224/ORB_SLAM2/Examples/ROS/ORB_SLAM2/map.bin");//load the mapros::spin();// Stop all threadsSLAM.Shutdown();SLAM.SaveMap("map.bin"); //save the map// Save camera trajectorySLAM.SaveKeyFrameTrajectoryTUM("KeyFrameTrajectory.txt");]]></content>
      <categories>
        <category>slam</category>
      </categories>
      <tags>
        <tag>slam实现</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++学习（4）--数据的共享与保护]]></title>
    <url>%2F2019%2F09%2F10%2FC%2B%2B%E5%AD%A6%E4%B9%A0%EF%BC%884%EF%BC%89.md%2F</url>
    <content type="text"><![CDATA[1 标识符的作用域与可见性1.1 作用域作用域是一个标识符在程序正文中有效的区域。 (1) 函数原型作用域 在函数原型声明时形式参数的作用范围就是函数原型作用域。 (2) 局部作用域 函数形参列表中形参的作用域，从形参列表中的声明处开始，到整个函数体结束之处为止。 函数体内声明的变量，其作用域从声明处开始，一直到声明所在的块结束的大括号为止。 具有局部作用域的变堡也称为局部变量。 (3) 类作用域 类可以被看成是一组有名成员的集合，类$ X $的成员 $m$ 具有类作用域，对 $m $的访问方式有如下 3 种。(1) 如果在 $X $的成员函数中没有声明同名的局部作用域标识符，那么在该函数内可以直接访问成员 $m $。也就是说$m $在这样的函数中都起作用。(2) 通过表达式 $x.m $或者$ x::m$ 。这正是程序中访问对象成员的最基本方法。(3) 通过 ptr-&gt;m 这样的表达式，其中 ptr 为指向 X 类的一个对象的指针。 (4) 命名空间作用域 具有命名空间作用域的变量也称为全局变量。 123456789101112131415161718192021222324252627//作用域实例#include &lt;iostream&gt;using namespace std;int i; //在全局命名空间中的全局变量namespace Ns&#123; int j; //在 NS 命名空间中的全局变量&#125;// 主函数int main()&#123; i = 5; //为全局变量 i 赋值 Ns::j=6; //为全局变星]赋值 &#123; using namespace Ns; //使得在当前块中可以直接引用 Ns 命名空间的标识符 int i; //局部变量,局部作用域 i = 7; cout&lt;&lt;"i="&lt;&lt;i&lt;&lt;endl; //输出 7 cout&lt;&lt;"j="&lt;&lt;j&lt;&lt;endl; //输出 6 &#125; cout&lt;&lt;"i="&lt;&lt;i&lt;&lt;endl;//输出 5 return 0;&#125; 1.2 可见性从标识符引用的角度，来看标识符的有效范围，即标识符的可见性。程序运行到某一点，能够引用到的标识符，就是该处可见的标识符。 作用域可见性的一般规则如下： 标识符要声明在前，引用在后。 在同一作用域中，不能声明同名的标识符。 在没有互相包含关系的不同的作用域中声明的同名标识符，互不影响。 如果在两个或多个具有包含关系的作用域中声明了同名标识符，则外层标识符在内层不可见。 2 对象的生存期对象(包括简单变量)都有诞生和消失的时刻。对象从诞生到结束的这段时间就是它的生存期。 2.1 静态生存期如果对象的生存期与程序的运行期相同，则称它具有静态生存期。在命名空间作用域中声明的对象都是具有静态生存期的。如果要在函数内部的局部作用域中声明具有静态生存期的对象，则要使用关键字 $static$ 。 2.2 动态生存期在局部作用域中声明的具有动态生存期的对象，习惯上也称为局部生存期对象。局部生存期对象诞生于声明点，结束于声明所在的块执行完毕之时。 12345678910111213141516171819202122232425262728293031323334353637//变量的生存期与可见性#include&lt;iostream&gt;using namespace std;int i=1; //i为全局变量，具有静态生存期void other()&#123; //a,b为静态局部变量，具有全局寿命，局部可见，只第一次进入函数时被初始化 static int a=2; static int b; //c为局部变量，具有动态生存期，每次进入函数时都初始化 int c=10; a+=2; i+=32; c+=5; cout&lt;&lt;"---OTHER---"&lt;&lt;endl; cout&lt;&lt;" i: "&lt;&lt;i&lt;&lt;" a: "&lt;&lt;a&lt;&lt;" b: "&lt;&lt;b&lt;&lt;" c: "&lt;&lt;c&lt;&lt;endl; b=a;&#125;int main()&#123; //a为静态局部变量，具有全局寿命，局部可见 static int a; //b,c为局部变量，具有动态生存期 int b=-10; int c=0; cout&lt;&lt;"---MAIN---"&lt;&lt;endl; cout&lt;&lt;" i: "&lt;&lt;i&lt;&lt;" a: "&lt;&lt;a&lt;&lt;" b: "&lt;&lt;b&lt;&lt;" c: "&lt;&lt;c&lt;&lt;endl; c+=8; other(); cout&lt;&lt;"---MAIN---"&lt;&lt;endl; cout&lt;&lt;" i: "&lt;&lt;i&lt;&lt;" a: "&lt;&lt;a&lt;&lt;" b: "&lt;&lt;b&lt;&lt;" c: "&lt;&lt;c&lt;&lt;endl; i+=10; other(); return 0;&#125; 输出 12345678---MAIN--- i: 1 a: 0 b: -10 c: 0---OTHER--- i: 33 a: 4 b: 0 c: 15---MAIN--- i: 33 a: 0 b: -10 c: 8---OTHER--- i: 75 a: 6 b: 4 c: 15 1234567891011121314151617181920212223242526272829303132333435363738394041424344//具有静态和动态生存期对象的时钟程序#include&lt;iostream&gt;using namespace std;class Clock&#123; //时钟类定义 public: //外部接口 Clock(); void setTime(int newH,int newM,int newS); //3个形参均具有函数原型作用域 void showTime(); private: //私有数据成员 int hour,minute,second;&#125;; //时钟类成员函数的实现Clock::Clock():hour(0),minute(0),second(0)&#123;&#125; //构造函数 void Clock::setTime(int newH,int newM,int newS)&#123; //3个形参均具有局部作用域 hour=newH; minute=newM; second=newS;&#125; void Clock::showTime()&#123; cout&lt;&lt;hour&lt;&lt;":"&lt;&lt;minute&lt;&lt;":"&lt;&lt;second&lt;&lt;endl;&#125;Clock globClock; //声明对象globClock，具有静态生存期，命名空间作用域 //由默认构造函数初始化为0：0：0int main()&#123; //主函数 cout&lt;&lt;"First time output:"&lt;&lt;endl; //引用具有命名空间作用域的对象globClock globClock.showTime(); //对象的成员函数具有类作用域 //显示0：0：0 globClock.setTime(8,30,30); //将时间设置为8：30：30 Clock myClock(globClock); //声明具有块作用域的对象myClock //调用复制构造函数，以globClock为初始值 cout&lt;&lt;"Second time output:"&lt;&lt;endl; myClock.showTime(); //引用具有块作用域的对象myClock //输出8:30:30 return 0; &#125; 输出 1234First time output:0:0:0Second time output:8:30:30 3 类的静态成员3.1 静态数据成员如果某个属性为整个类所共有，不属于任何一个具体对象，则采用 static 关键字来声明为静态成员。 类属性是描述类的所有对象共同特征的一个数据项，对于任何对象实例，它的属性值是相同的。 静态数据成员具有静态生存期。由于静态数据成员不属于任何一个对象，因此可以通过类名对它进行访问，一般的用法是”类名::标识符”。 3.2 静态函数成员所谓静态成员函数就是使用 static 关键字声明的函数成员。同静态数据成员一样，静态成员函数也属于整个类，由同一个类的所有对象共同拥有，为这些对象所共享。 静态成员函数可以直接访问该类的静态数据和函数成员。而访问非静态成员，必须通过对象名。 123456789101112131415161718192021222324252627282930313233343536373839404142//具有静态数据和函数成员的Point类#include&lt;iostream&gt;using namespace std;class Point&#123; //Point类定义public: //外部接口 Point(int x=0,int y=0):x(x),y(y)&#123; //构造函数 //在构造函数中对count累加，所有对象共同维护同一个count count++; &#125; Point(Point &amp;p)&#123; //复制构造函数 x=p.x; y=p.y; count++; &#125; ~Point()&#123;count--;&#125; int getX()&#123;return x;&#125; int getY()&#123;return y;&#125; static void showCount()&#123; //静态函数成员 cout&lt;&lt;" Object count="&lt;&lt;count&lt;&lt;endl; &#125;private: //私有数据成员 int x,y; static int count; //静态数据成员声明，用于记录点的个数&#125;;int Point::count=0; //静态数据成员定义和初始化，使用类名限定int main()&#123; //主函数 Point::showCount(); Point a(4,5); //定义对象a，其构造函数会使count增1 cout&lt;&lt;"Point A: "&lt;&lt;a.getX()&lt;&lt;","&lt;&lt;a.getY(); Point::showCount(); //输出对象个数 Point b(a); //定义对象b，其构造函数会使count增1 cout&lt;&lt;"Point B: "&lt;&lt;b.getX()&lt;&lt;","&lt;&lt;b.getY(); Point::showCount(); //输出对象个数 return 0;&#125;]]></content>
      <categories>
        <category>语言学习</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ORBSLAM2 论文]]></title>
    <url>%2F2019%2F09%2F09%2FORBSLAM2%E8%AE%BA%E6%96%87%2F</url>
    <content type="text"><![CDATA[论文原文下载：https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7946260 摘要ORB-SLAM2是基于单目、双目和RGB-D相机的一套完整的SLAM方案。它能够实现地图重用、回环检测和重新定位的功能。无论是在室内的小型手持设备，还是到工厂环境的无人机和城市里驾驶的汽车，ORB-SLAM2都能够在标准的CPU上进行实时工作。ORB-SLAM2在后端上采用的是基于单目和双目的光束法平差优化（BA）的方式，这个方法允许米制比例尺的轨迹精确度评估。此外，ORB-SLAM2包含一个轻量级的定位模式，该模式能够在允许零点漂移的条件下，利用视觉里程计来追踪未建图的区域并且匹配特征点。 我们用29个广泛使用的公共数据测试的结果显示，在大多数情况下，本文方案比此前方案精度更高，此外，我们开源了ORB-SLAM2源代码，不仅仅是为了整个SLAM领域，同时也希望能够为其他领域研究者提供一套SLAM的解决方案。 I. 引言SLAM（同时定位与地图重建）在过去的20年中，一直是计算机视觉和机器人领域的热门话题，同时也吸引了很多高科技公司的关注。SLAM技术是在未知的环境当中建立一个地图并且能够在地图当中实时的定位。在不同类型的传感器当中，相机十分廉价，并且能够提供丰富的环境信息，受到研究者的青睐。相机提供的图像信息可以用作鲁棒的和精确的位置识别。位置识别是SLAM系统中回环检测的关键模块（例如，当传感器检测到一个已经建好图的位置的时候，可以进行修正在探索过程中的误差）以及，能够修正由于剧烈的震动或者在系统进行初始化的时候在相机跟踪失败后的重新定位。因此以相机为核心的视觉SLAM在过去的一年中得到快速的发展。 视觉SLAM仅仅通过一个单目相机就能够完成。单目相机也是最便宜也是最小巧的传感器设备。然而深度信息无法从单目相机中观测到，地图的尺度和预测轨迹是未知的。此外，由于不能从第一帧当中进行三角测量化，单目视觉SLAM系统的启动往往需要多个视角或者滤波技术才能产生一个初始化的地图。最后，单目SLAM可能会造成尺度漂移,以及在探索的过程中执行纯旋转的时候可能会失败。通过使用一个双目或者RGB-D相机将会解决这些问题，并且能够成为一种更加有效的视觉SLAM的解决方案。 在这篇文章当中，我们在单目ORB-SLAM[1]的基础上提出ORB-SLAM2，有以下贡献： 这是首个基于单目、双目和RGB-D相机的开源SLAM方案，这个方案包括，回环检测、地图重用和重定位。 我们的RGB-D结果说明，光速法平差优化（BA）比ICP或者光度和深度误差最小方法的更加精确。 通过匹配远处和近处的双目匹配的点和单目观测，我们的双目的结果比直接使用双目系统更加精确。 针对无法建图的情况，提出了一个轻量级的定位模式 ，能够更加有效的重用地图。 ​ (a)双目输入：带有多次回环检测的城市环境轨迹和稀疏重建 (b) RGB-D输入：房间关键帧和稠密点云已经一次回环检测图，这些点云通过对深度图的关键帧的位姿进行映射得到，不进行渲染(融合) 图1 是ORB-SLAM2处理双目和RGB-D输入评估相机的轨迹并建图。这个系统能够保证在高精度和鲁棒性的前提下，做到在标准CPU上进行实时的，回环检测，重定位以及地图重用。 图a中显示的是双目和RGB输入下的ORBSLAM2的输出。双目例子显示的是最后轨迹和稀疏重建的地图。这里的数据集来源于KITTI的Sequence00数据集。这个城市数据集是ORB-SLAM2多次成功提取特征，并且回环检测而来。 RGB-D例子是来源于TUM 的RGB-D 数据库中的fr1_room的数据集，并且进行关键帧的位姿评估而来。通过评估关键帧的位姿，映射深度图，最终形成一个稠密的点云图。指的注意的一点是，ORB-SLAM2虽不像Kinect Fusion一样进行数据融合，但是却能够很精确的估计关键帧的位姿。更多的例子在附件视频中展示。在余下的篇章当中，我们将会在第二部分讨论相关的工作。在第三部分谈论ORB-SLAM2系统框架。第四部分评价ORB-SLAM2，第五部分得出结论。 II. 相关工作在这个章节，我们将会讨论双目和RGB-D SLAM的相关工作。评估部分我们放在第四部分，本章我们主要讨论的是SLAM的方法。 2.1 双目SLAM最早研究双目SLAM方案的是Paz 等人[5]，基于条件独立分割和扩展SLAM，其显著特点是能够在大场景中运行。更重要的是，这是第一个使用近特征点和远特征点（例如，由于双目相机差异较小，导致点的深度不能准确的估计）的双目SLAM系统，使用一个逆深度参数进行估计。经验值表明如果深度小于40倍双目的基线，那么这个点就能被三角测量化。我们就是跟随的这样思想来处理远近不同的特征点，具体解释放在第三部分。 目前大多数双目系统都是基于特征匹配和局部BA优化的方式，来获得尺度。Strasdat等人[8]采用在一个输出窗口的关键帧[7]和位姿的BA联合优化算法。在全局不一致性的情况下，通过限制窗口的大小的方式，实现了约束了时间的复杂程度的目的。Mei等人[9]在限定时间复杂度的条件下，使用路标和位姿相关性的方式的实现了RSLAM解决方案，并且提出和实现了在活动的区域的BA优化算法。即使在全局不一致的条件下，RSLAM也能够进行闭环，同时会扩大回环两侧的活动区域。 Pire等人[10]把局部的BA运用到了邻近S-PTAM上面来，但是，这种方法缺少大量的回环检测。与此相似的是，我们对局部关键帧采用BA优化，因此，这个地图的大小和复杂程度的大小是独立的，进而，我们可以在一个大场景当中运行。然而，我们目标是建立一个全局不变的地图。因此，我们的系统首先在回环的两端执行。这与RSLAM很相似，以便于能够使用旧的地图进行定位，之后进行位姿估计，即将回环产生的累积漂移最小化。 Engel等人[11]提出邻近双目LSD-SLAM方案，采用的是一种直接的半稠密方法，最小化高梯度的图像区域中的光度误差。这种方法希望能够在不依赖特征提取的条件下，能够在纹理不清或者模糊运动的过程中获得更高的鲁棒性。然而，直接法的性能会由于滚动（卷帘）快门，或者非朗伯反射的未建模的因素影响而下降。 2.2 RGB-D SLAM最早和最著名的RGB-DSLAM系统是有Newcombe等人[4]提出的KinectFusion，这种方法将深度数据进行融合，深度数据来源于传感器到深度模型，常常使用ICP算法来跟踪相机的位姿。由于体积的表现形式和缺乏回环检测，这种算法只能工作在小的工作空间。Whelan 等人[12]提出的Kintinuous能够在大环境中运行。它通过使用一个滚动循环缓冲器和包括使用位置定位和位姿优化来达到回环检测的目的。 第一个开源的RGB-DSLAM方案是由Endres[13]提出的，这是一种基于特征点提取的系统，他的前端采用提取和匹配特征点和ICP来计算帧与帧之间的运动。 后端采用位姿图优化的方式，回环检测约束条件来源于一个启发式搜索。相似的是，Kerl 等人[14]提出的DVO-SLAM，是在关键帧与关键帧之间的优化位姿图，视觉里程计通过计算最小化光度和深度误差来计算约束条件。DVO-SLAM同时在以前的所有帧当中，搜索回环的候选者，而不依赖于位置识别。 Whelan等人[15]提出的邻近ElasticFusion算法，是建立在基于确定环境的地图。这是一种以地图为中心的方法。这种方法忽略了非刚性形变地图的位姿和回环检测的性能，也是不是一个标准的位姿图优化。这种方法在重建和定位的精度都是十分优秀的，但是目前的应用十分有限对于一个房间大小的地图，由于在地图当中面元的数量影响计算的复杂程度。 Strasdat等人[8]提出ORB-SLAM2这种方法，这个方法使用深度信息去合成一个三维坐标，能够精确的提取到一副图像的信息。ORB-SLAM2能够处理来自双目和RGB-D的图像，与上述方法不同的是，我们的后端是用的BA算法，来建立一个全局的稀疏的地图重建，因此我们的方法更加轻量级并且能够在标准的CPU上面运行。我们的目标是长时间并且全局精准定位，而不是建立一个有很多细节的稠密地图。然而，高精度的关键帧的位姿，能够融合深度图像以及在计算中得到精准的重建，或者能够处理所有的关键帧和深度图，以及所有的BA并且得到一个精准的3D模型。 III. ORBSLAM2针对双目相机和RGB-D相机的ORB-SLAM2建立在单目ORB-SLAM的基础上，它的核心组件，如图2所示。 图2 ORB-SLAM2由三个平行的线程组成，跟踪，局部建图和回环检测。在一次回环检测后，会执行第四个线程，去执行BA优化。跟踪的线程在双目或者RGB-D输入之前进行，因此剩下的系统模块能够跟传感器模块独立运行。单目的ORB-SLAM2工作图也是这幅图。 这个系统主要有3个并行的线程： 1、通过寻找对局部地图的特征，并且进行匹配，以及只运用BA算法来最小化重投影误差，进行跟踪和定位每帧的相机。 2、运用局部的BA算法设置局比地图并且优化。 3、回环检测检能够通过执行位姿图的优化来更正累计漂移误差。在位姿优化之后，会启动第四个线程来执行全局BA算法，来计算整个系统最优结构和运动的结果。 这个系统是一个基于DBoW2[16]的嵌入式位置识别模型，来达到重定位，防止跟踪失败（如遮挡），或者已知地图的场景重初始化，和回环检测的目的。这个系统产生关联可见的图[8]，连接两个关键帧的共同点，连接所有关键帧的最小生成树方面。这些关键帧的图结构能够得到一个关键帧的局部的窗口，以便于跟踪和局部建图，并且在大型的环境当中的回环检测部分，作为一种图优化的结构。 这个系统使用相同的ORB特征进行跟踪，建图和位置识别的任务。这些特征在旋转不变和尺度不变性上有良好的鲁棒性，同时对相机的自动增益，曝光和光线的变化表现出良好的稳定性。并且能够迅速的提取特征和进行匹配，能够满足实时操作的需求，能够在基于词袋的位置识别过程中，显示出良好的精度[18]。 在本章的剩下的部分当中，我将会展示双目或者深度信息是如何利用，和到底会影响系统中的那些部分。对每个系统块更详尽的描述，可参见论文[1] 3.1 单目、近处双目和远处双目特征点ORB-SLAM2作为一种基于特征提取的方法，在一些关键的位置上的提取进行预处理，如图2b所示，系统的所有运行都是基于输入图像的特征展开，而不依赖于双目或者RGB-D的相机。我们的系统处理单目或者双目的特征点，分成远处特征点和近处特征点两类。 双目特征点 通过三个坐标定义当中，是这个左边图像的坐标，是右图当中的水平坐标。对于双目相机而言，我们提取两幅图像当中的ORB特征，对于每个左边的ORB特征我们对其匹配到右边的图像中。这对于建设双目图像校正十分有效，因此极线是水平的。之后我们会在左边的图像产生双目的ORB特征点，和一条水平的线向右边的图像进行匹配，通过修补相关性来重新定义亚像素。对于RGB-D相机，正如Strasdat等人[8]所言，我们提取在图像通道上提取ORB特征点，。我们将深度值和已经处理的深度地图，和基线在结构光投影器和红外相机进行匹配，对每一帧的图像与右边图像的坐标系进行融合。这是kinect和华硕 Xtion 精度大约是8cm。 近双目特征点的定义是：匹配的深度值小于40倍双目或者RGB-D的基线，否则的话，是远特征点。近的特征点能够从一帧的深度值能够三角测量化，是精确的估计，并且能够提供尺度，平移和旋转的信息。另外一方面，远的特征点，能够提供精确的旋转信息，但是很少的尺度和平移信息。当提供多视图的时候，我们才能三角化那些远的点。 单目的特征点通过右边图像的两个坐标当中的定义，必须保证所有的ORB特征是一致的，否则双目特征点的提取将不能够完整，或者在RGB-D的情况下，有产生一个无效的深度值。这些点仅能够从多视图中三角测量化并且不能够提供尺度信息，但是可以提供旋转和平移的估计信息。 3.2 系统引导使用双目和RGB-D相机的主要优势在于，我们可以直接获得深度信息，我们不需要像单目情况中那样做一个特定的SFM初始化。在系统初始化的时候，我们就创造了一个关键帧（也就是第一帧），将他的位姿进行初始化，从所有的立体点中创造一个初始化地图。 3.3 使用单目或者双目光束优化法我们的系统采用光束优化法（BA），优化在跟踪过程（纯运动BA）中相机的位姿，优化本地窗口的关键帧和局部地图的特征点（局部BA），并且在回环检测之后优化所有的关键帧和特征点（全局BA）。我们在g2o当中使用Levenberg-Marquadt方法[19]。 纯运动BA，优化相机旋转矩阵和位置，最小化世界坐标系下匹配3D点云和特征点（单目的或双目的，其中）的重投影误差：$${\mathbf{R}, \mathbf{t}}=\underset{\mathbf{R}, \mathbf{t}}{\operatorname{argmin}} \sum_{i \in \mathcal{X}} \rho\left(\left|\mathbf{x}{(\cdot)}^{i}-\pi{(\cdot)}\left(\mathbf{R} \mathbf{X}^{i}+\mathbf{t}\right)\right|{\Sigma}^{2}\right)$$在这个式子当中，是强健的Huber的cost函数，是协方差矩阵，关联对于特征点的尺度。这个投影函数，单目的时候使用，修正双目的时候用，他们的定义如下：$$\pi{\mathrm{m}}\left(\left[\begin{array}{l}{X} \ {Y} \ {Z}\end{array}\right]\right)=\left[\begin{array}{l}{f_{x} \frac{X}{Z}+c_{x}} \ {f_{y} \frac{Y}{Z}+c_{y}}\end{array}\right]$$ $$\pi_{\mathrm{s}}\left(\left[\begin{array}{l}{X} \ {Y} \ {Z}\end{array}\right]\right)=\left[\begin{array}{c}{f_{x} \frac{X}{Z}+c_{x}} \ {f_{y} \frac{Y}{Z}+c_{y}} \ {f_{x} \frac{X-b}{Z}+c_{x}}\end{array}\right]$$ 在这个式子当中是焦距，是主要点（象点），b是基线，所有的这些参数都是通过标定获得。 局部BA 采用一系列可用的关键帧和所有在关键帧可观点，所有的其他关键帧是，而不是，观察当中所有的特征点用于代价函数，但是在优化中是固定的。定义为中关键帧k的一系列匹配特征点，这个优化问题如下：$$\begin{aligned}\left{\mathbf{X}^{i}, \mathbf{R}{l},\right.&amp;\left.\mathbf{t}{l} | i \in \mathcal{P}{L}, l \in \mathcal{K}{L}\right}=\ &amp; \underset{\mathbf{X}^{i}, \mathbf{R}{l}, \mathbf{t}{l}}{\mathbf{R}} \sum_{k \in \mathcal{K}{L} \cup \mathcal{K}{F}} \sum_{j \in \mathcal{X}_{k}} \rho(E(k, j)) \end{aligned}$$ $$E(k, j)=\left|\mathbf{x}{(\cdot)}^{j}-\pi{(\cdot)}\left(\mathbf{R}{k} \mathbf{X}^{j}+\mathbf{t}{k}\right)\right|_{\Sigma}^{2}$$ 全局BA是 局部光束法的一个特例，这个方法除了初始帧所有的关键帧和点在地图当中都会被优化.初始帧是固定的，用来消除随机化。 3.4 闭环检测和全局BA回环检测有两步：首先，一个回环信息被确定检测到，然后利用这个回环纠正和优化位姿图。相比于单目的ORB-SLAM中可能出现尺度漂移的地方[20]，这个双目或者深度的信息将会使得尺度信息可观测。并且，几何校验和位姿图优化将不再需要处理尺度漂移，而且是基于刚体变换的，而不是基于相似性。 在ORB-SLAM2的位姿优化后，我们包含一个全局的BA优化，为了实现一个优化方案，我们必须采用一个独立的线程，允许系统能够持续的建图，并且检测到回环信息。但是这将会再次触发全局BA优化与当前地图的合成。如果在优化运行时检测到新的循环，我们将中止优化并继续关闭循环，这将再次启动完整的BA优化。当完整的BA结束时，我们需要将更新的关键帧子集和由完整BA优化的点与未更新的关键帧和在优化运行时插入的点合并。最后通过更新更新关键帧校正（例如，这个变换从未优化到已优化）到一个未更新关键帧通过生成树当中。根据校正参考帧来改造呢些未更新的特征点。 3.5 关键帧的插入ORB-SLAM2遵循在单目ORB-SLAM中提的法则，即经常插入关键帧并且剔除上一帧的冗余。在远近特征点的差异为我们插入一个新的关键帧提供了条件，这在大场景的条件下是至关重要的，如图3所示。 图3 高速公路的跟踪点。绿色的特征点深度小于40倍双目的基线，蓝色特征点大于40倍双目的基线，在这种数据集当中，需要插入大量的关键帧，以便于能够让近处的特征点更加精确的估计平移和尺度，远处的特征点来估计方向，但是不能够计算平移和尺度。 在这样的环境中，我们需要一个大量的近点用以精确估计平移，因而如果这个被跟踪近点小于并且这个帧将会创造个新邻近立体点，这个系统将会插入一个新的关键帧，我们经验值认为，当和的条件下我们效果最好。 3.6 定位模式ORB-SLAM2包括一个定位模式，该模式适用于轻量级以及在地图已知情况下长期运行，只要那个环境没有发生剧烈变化。在该模式中，局部建图和回环检测的线程中是停用的，并且这个相机始终都是在通过追踪进行重定位。在这个模式下，追踪模块使用视觉里程计进行匹配图像的点云。视觉里程计匹配在当前帧的ORB算子和由双目或者深度相机收集的3D点云。这些匹配使得在没有地图的区域也能够精确重新定位，但是漂移将会被累加。地图点云匹配要确保在一个已经存在的地图当中零漂移定位，这个模型在附带的video当中会显示。 IV. 评估我们使用三个著名的数据集来评估ORB-SLAM2的算法的性能。我们在一台16G的RAM，Intel Core i7-4790的台式机运行，以低于传感器的帧率，对处理跟踪时间求平均。我们运行数据集5次，取中间值，来消除多线程系统的不确定性。我们开源了在运行这几个系统的数据集的方法包括标定具体操作实现。 4.1 KITTI数据集KITTI数据集包含双目数据，这些数据从一个正在高速公路上行驶的车上采集到的。这个双目传感器有个小于54厘米的基线并且在在1392*512像素上，以10Hz的采样速率进行采样，其中序列00,02,05,06，和09包含回环。我们的ORB-SLAM2能够检测出回环并且能够地图重用，除了09序列以外，09序列的回环只发生在尾端少数的几帧当中。表1显示的这个结果11个训练数据，这是一个公开的真实数据，对比于原先的LSD-SLAM算法，我们展示了的双目SLAM系统测试数据结果。我们使用两个不同的米制，均方根误差在论文[3]中提到，并且取平均相关平移和旋转误差在论文[2]，我们的系统在大多数序列当中比双目的LSD-SLAM要优秀很多，并且能够获得的相关误差低于1%。这个序列01如图3所示，是一个高速公路的序列，作为训练集，以及转换误差。转换误差是在这个序列当中难以评估的，因为只有几个很近的点能够被侦测，由于很高的速度和较低的帧率。然而这个方向能够被精确的评估，获得的误差是每100米做0.21度。很多较远的点能够被检测，如图4所示，显示了一些评估的例子。 表1两种SLAM在测试KITT，I数据的精度对比 图4 在KITTE数据集01,05,07和08数据集，估计轨迹（黑色线）和以及实际运动（红色线） 4.2 EuRoC 数据集EuRoC 数据集包含了11个双目的序列，通过一个微型飞行器（MAV）采集到的数据，飞行在两个不同的房间和大量的工业环境。这个双目传感器有一个小于11cm的基线和能够提供20HZ的WVGA格式的图像，这个序列分成，简单、中等、和困难，这取决于MAV（微型飞行器）的速度，照明和场景的纹理。在所有的序列当中，MAV（微型飞行器）再次访问这个环境的时候，ORB-SLAM2能够重用地图，回环检测。这个表格2显示的是ORB-SLAM2的最小均方误差的绝对值变换，对于所有序列而言。相比较对双目的LSD-SLAM的结果。 ORB-SLAM2能够实现一个厘米级精准的定位，并且比双目的LSD-SLAM更加的精确。跟踪部分可能会在V2_ 03_ difficul，序列当中跟丢，由于一些运动模糊。在第22篇论文解释的情况，这个序列在处理的过程中是使用IMU信息，如图5所示，显示的一些估计轨迹对真实的世界相比的例子。 图5 在EuRoC V1_02_medium，V2_02_medium，MH_03_medium和MH_05_数据集测试结果，其中估计轨迹（黑色）实际运动轨迹（红色） 4.3 TUM RGB-D数据集TUM RGB-D数据集包含一些室内的序列，在不同的纹理下，不同的光照和不同的结构条件，从RGB-D传感器采集到的数据中分别去评估物体的重建和SLAM/视觉里程计的性能。和大多数RGB-DSLAM方法一样，我们将实验结果展示在一个序列子集当中，在表格3当中，我们比较我们的精准性和其他方法，例如ElasticFusion，Kintinuous，DVO-SLAM以及RGB-DSLAM，ORB-SLAM2是唯一一种基于光束流差法，并且比其他的方法都更加优秀。我们已经注意到RGB-DSLAM，深度地图对于freiburg2序列有一个4%的尺度误差，误差可能来自错误的标定，我们已经在运行过程中，进行了一定程度的补偿。这能够部分解释我们取得好的结果的原因。图6显示的点云的结果来源于后端映射的传感器深度的地图，从计算关键帧的位姿在四个序列当中。实验的结果显示，ORB-SLAM2很好的展示了桌子和海报的轮廓线，以及高精度的重定位。 图6 TUM RGB-D数据的fr3office, fr1 room, fr2 desk and fr3 nst 序列的通过评估关键帧的位姿和深度图进行稠密的点云重建图 V. 结论本文呈现了一个基于于单目，双目和RGB-D传感器的完整SLAM框架，在实时和标准的CPU的前提下能够进行重新定位和回环检测，以及地图的重用。在实验当中，我们关心的是在大场景中建立可用的地图和长期的定位。与此前的SLAM方案进行对比，在大多数的情况下，ORB-SLAM2展现出一样好的精确程度。 值得注意的是，我们的RGB-D实现的结果显示，如果相机的定位精度更好，那么BA将会比直接法或者ICP的方法更好，将会减少一些额外的计算量。我们开放了我们系统的源码，和一些例子和指导，以便于能够更加方便为其他研究者而使用。未来的方向可能包含，测试更多的序列，多视角相机，鱼眼相机或者其他全相相机的，大场景的稠密重建，以及联合建图或者增加运动模糊的鲁棒性。]]></content>
      <categories>
        <category>slam</category>
      </categories>
      <tags>
        <tag>slam理论</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++学习（3）--类与对象]]></title>
    <url>%2F2019%2F09%2F05%2FC%2B%2B%E5%AD%A6%E4%B9%A0%EF%BC%883%EF%BC%89%2F</url>
    <content type="text"><![CDATA[1 面向对象程序设计的基本特点 抽象：解释类与对象之间关系的词。类与对象之间的关系就是抽象的关系。一句话来说明：类是对象的抽象，而对象则是类得特例，即类的具体表现形式。 封装：封装是面向对象编程的核心思想。将对象的属性和行为封装起来,其载体就是类,类通常会对客户隐藏其实现细节,这就是封装的思想。 继承：子类继承父类，可以继承父类原有的属性和方法，也可以增加其他的属性和方法，可以直接重写父类中的某些方法。 多态：多态性一般是指在父类中定义的方法被子类继承后，可以表现出不同的行为。这使得同一个方法在父类及其各个子类中具有不同的语义。 2 类和对象2.1 类的定义语法形式如下： 123456789class 类名称&#123;public: 外部接口private: 私有成员protected: 保护型成员&#125; 2.2类成员的访问控制public:公有类型，类的外部接口。 private:私有类型，只能被本类的成员函数访问，来自类外部的任何访问都是非法的。 protected:保护类型，和私有类型类似，差别在于继承过程中对产生的新类的影响不同。 2.3 对象类的对象是该类的某一特定实体，即类类型的变量。 声明形式： 12类名 对象；Clock myClock； 类中成员互访：直接使用成员名 类外访问：使用“对象名.成员名” 方式访问public属性成员 2.4 类的成员函数实现形式 1234返回值类型 类名：：函数成员名（参数表）&#123; 函数体&#125; 例子 12345678910111213141516171819202122232425262728293031323334353637//设置时钟#include &lt;iostream&gt;using namespace std;class Clock&#123; //时钟类的定义public: //外部接口 void setTime(int newH=0, int newM=0, int newS=0); void showTime();private: //私有数据成员 int hour,minute,second;&#125;;//时钟类函数的实现void Clock::setTime(int newH, int newM, int newS) &#123; hour = newH; minute = newM; second = newS;&#125;inline void Clock::showTime() &#123; cout&lt;&lt;hour&lt;&lt;":"&lt;&lt;minute&lt;&lt;":"&lt;&lt;second&lt;&lt;endl;&#125;//主函数int main()&#123; Clock myClock; //定义对象myClock cout&lt;&lt;"First time set and output:"&lt;&lt;endl; myClock.setTime(); myClock.showTime(); cout&lt;&lt;"Second time set and output:"&lt;&lt;endl; myClock.setTime(22,10,30); myClock.showTime(); return (0);&#125; 3 构造函数和析构函数3.1 构造函数构造函数的作用是在对象被创建时利用特定的值构造对象，将对象初始化为一个特定的状态。 123456789101112131415161718192021222324252627282930313233343536373839404142434445//设置时钟#include &lt;iostream&gt;using namespace std;class Clock&#123; //时钟类的定义public: //外部接口 Clock (int newH, int newM, int newS); //构造函数 void setTime(int newH=0, int newM=0, int newS=0); void showTime();private: //私有数据成员 int hour,minute,second;&#125;;//构造函数的实现Clock::Clock(int newH, int newM, int newS) &#123; hour = newH; minute = newM; second = newS;&#125;//时钟类函数的实现void Clock::setTime(int newH, int newM, int newS) &#123; hour = newH; minute = newM; second = newS;&#125;inline void Clock::showTime() &#123; cout&lt;&lt;hour&lt;&lt;":"&lt;&lt;minute&lt;&lt;":"&lt;&lt;second&lt;&lt;endl;&#125;//主函数int main()&#123; Clock myClock(1,2,3); //定义对象myClock cout&lt;&lt;"First time set and output:"&lt;&lt;endl; myClock.showTime(); cout&lt;&lt;"Second time set and output:"&lt;&lt;endl; myClock.setTime(22,10,30); myClock.showTime(); return (0);&#125; 3.2 复制构造函数复制构造函数是一种特殊的构造函数，其形参是本类的对象的引用。作用是使用一个已经存在的对象（由复制构造函数的参数指定），去初始化同类的一个新的对象。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748//设置时钟#include &lt;iostream&gt;using namespace std;class Point&#123; //Point 类的定义public: // 外部接口 Point(int xx=0, int yy=0)&#123; // 构造函数 x=xx; y=yy; &#125; Point(Point &amp;p); //复制构造函数 int getX()&#123; return x; &#125; int getY()&#123; return y; &#125;private: // 私有数据 int x, y;&#125;;// 成员函数的实现Point::Point(Point &amp;p) &#123; x=p.x; y=p.y; cout&lt;&lt;"呼叫复制构造函数"&lt;&lt;endl;&#125;// 形参为Point类对象的函数void fun1(Point p)&#123; cout&lt;&lt;p.getX()&lt;&lt;endl;&#125;//返回值为Point类对象的函数Point fun2()&#123; Point a(1,2); return a;&#125;// 主函数int main()&#123; Point a(4,5); //第一个对象a Point b=a; //用法1，用a初始化b cout&lt;&lt;b.getX()&lt;&lt;endl; fun1(b); // 用法2，对象b作为fun1的实参 b=fun2(); // 用法3，函数的返回值是类对象，函数返回时，调用复制构造函数 cout&lt;&lt;b.getX()&lt;&lt;endl; return (0);&#125; 3.3 析构函数作用与构造函数正好相反，用来完成对象被删除前的一些清理工作。在对象生存期即将结束的时刻被自动调用，不接受任何参数，也没有返回值。 4 类的组合类的组合描述的是一个类内嵌套其他类的对象作为成员的情况，是一种包含与被包含的关系。 当创建类的对象时，如果这个类具有内嵌对象成员，那么各个内嵌对象将首先被自动创建。在创建对象时，既要对本类的基本类型数据成员进行初始化，又要对内嵌对象成员进行初始化。 例子 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768//Line 类的例子#include &lt;iostream&gt;#include &lt;cmath&gt; //数学函数using namespace std;class Point&#123; //Point 类定义public: Point(int xx=0, int yy=0)&#123; // 构造函数 x=xx; y=yy; &#125; Point(Point &amp;p); //复制构造函数 int getX()&#123; return x; &#125; int getY()&#123; return y; &#125;private: // 私有数据 int x, y;&#125;;// 成员函数的实现Point::Point(Point &amp;p) &#123; x=p.x; y=p.y; cout&lt;&lt;"呼叫复制构造函数"&lt;&lt;endl;&#125;// 类的组合class Line&#123; // Line类的定义public: Line(Point xp1, Point xp2); Line(Line &amp;l); double getLen() &#123; return len;&#125;private: Point p1, p2; double len;&#125;;// 组合类的构造函数Line::Line(Point xp1, Point xp2) :p1(xp1),p2(xp2)&#123; cout&lt;&lt;"呼叫Line的构造函数:"&lt;&lt;endl; double x= static_cast&lt;double&gt;(p1.getX()-p2.getX()); double y= static_cast&lt;double&gt;(p1.getY()-p2.getY()); len = sqrt(x*x+y*y);&#125;// 组合类的复制构造函数Line::Line(Line &amp;l):p1(l.p1),p2(l.p2) &#123; cout&lt;&lt;"呼叫Line的复制构造函数:"&lt;&lt;endl; len=l.len;&#125;// 主函数int main()&#123; Point myp1(1,1), myp2(4,5); Line line(myp1,myp2); Line line2(line); cout&lt;&lt;"Line的长度为:"&lt;&lt;endl; cout&lt;&lt;line.getLen()&lt;&lt;endl; cout&lt;&lt;"Line2的长度为:"&lt;&lt;endl; cout&lt;&lt;line2.getLen()&lt;&lt;endl; return (0);&#125;]]></content>
      <categories>
        <category>语言学习</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++学习（2）--函数]]></title>
    <url>%2F2019%2F09%2F04%2FC%2B%2B%E5%AD%A6%E4%B9%A0%EF%BC%882%EF%BC%89%2F</url>
    <content type="text"><![CDATA[1 函数的定义与使用1.1 函数定义的语法形式1234567类型说明符 函数名（含类型说明的形参表）&#123;​ 语句序列&#125; 1.2 函数的调用调用前先声明： 1类型说明符 函数名（含类型说明的形参表）; 再调用： 1函数名（实参表） 一般调用 12345678910111213141516//求x的n次方#include &lt;iostream&gt;using namespace std;double power(double x, int n);int main()&#123; cout &lt;&lt; "5 to the power 2 is "&lt;&lt; power(5,2) &lt;&lt;endl; return 0;&#125;double power(double x, int n)&#123; double val=1.0; while (n--) val *= x; return val;&#125; 嵌套调用 12345678910111213141516171819//求两个数平方和#include &lt;iostream&gt;using namespace std;int fun2(int m)&#123; return m*m;&#125;int fun1(int x, int y)&#123; return fun2(x)+fun2(y);&#125;int main()&#123; int a, b; cout&lt;&lt;"请输入两个数："; cin&gt;&gt;a&gt;&gt;b; cout&lt;&lt;"它们的平方和为："&lt;&lt;fun1(a,b)&lt;&lt;endl; return 0;&#125; 递归调用 1234567891011121314151617181920//求n的阶乘#include &lt;iostream&gt;using namespace std;unsigned fac(unsigned n)&#123; unsigned f; if (n==0) f=1; else f=fac(n-1)*n; return f;&#125;int main()&#123; unsigned n; cout&lt;&lt;"输入一个正整数："; cin&gt;&gt;n; unsigned y=fac(n); cout&lt;&lt;n&lt;&lt;"!="&lt;&lt;y&lt;&lt;endl; return 0;&#125; 1.3 函数的参数传递值传递（单项传递） 12345678910111213141516//交换两个数#include &lt;iostream&gt;using namespace std;void swap (int a, int b)&#123; int t = a; a=b; b=t;&#125;int main()&#123; int x=5, y=10; cout &lt;&lt; "x="&lt;&lt;x&lt;&lt;" y="&lt;&lt;y&lt;&lt;endl; swap(x,y); cout &lt;&lt; "x="&lt;&lt;x&lt;&lt;" y="&lt;&lt;y&lt;&lt;endl; return 0;&#125; 输出： 12x=5 y=10x=5 y=10 引用传递（双向） 12345678910111213141516//交换两个数#include &lt;iostream&gt;using namespace std;void swap (int &amp;a, int &amp;b)&#123; int t = a; a=b; b=t;&#125;int main()&#123; int x=5, y=10; cout &lt;&lt; "x="&lt;&lt;x&lt;&lt;" y="&lt;&lt;y&lt;&lt;endl; swap(x,y); cout &lt;&lt; "x="&lt;&lt;x&lt;&lt;" y="&lt;&lt;y&lt;&lt;endl; return 0;&#125; 输出： 12x=5 y=10x=10 y=5 2 C++系统函数 C++系统提供很多自带的函数，如数学函数，平方根（sqrt)，求绝对值（abs）等等。 只需要用include指令嵌入相应的头文件，就可以使用系统函数。如数学函数，只需在开头写： 1#include &lt;cmath&gt;]]></content>
      <categories>
        <category>语言学习</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++学习（1）--基础]]></title>
    <url>%2F2019%2F08%2F29%2FC%2B%2B%E5%AD%A6%E4%B9%A0%EF%BC%881%EF%BC%89%2F</url>
    <content type="text"><![CDATA[1 命名空间避免命名冲突 std是C++标准库的命名空间（ namespace）名 using namespace std表示打开std命名空间 12345678910111213#include &lt;iostream&gt;using namespace std;int main() &#123; cout &lt;&lt; "Hello!" &lt;&lt; endl; cout &lt;&lt; "Welcome to c++!" &lt;&lt; endl; return 0;&#125; 运行结果： Hello! Welcome to c++！ 2 基本运算12345678910111213141516#include &lt;iostream&gt;using namespace std;int main() &#123; const int PRICE = 30; // 整数常量 int num, total; // 初始化 double v, r, h; num = 10; // 赋值 total = num * PRICE; cout &lt;&lt; total &lt;&lt; endl; r = 2.5; h = 3.2; v = 3.14159 * r * r * h; cout &lt;&lt; v &lt;&lt; endl; return 0;&#125; 运行结果： 30062.8318 注意：1/2为0，1/2.0为0.5 。 3 数据输入输出 “&lt;&lt;”是预定义的插入符，作用在流类对象cout上便可以实现项标准输出设备输出。 1cout &lt;&lt; 表达式 &lt;&lt; 表达式... 标准输入是将提取符作用在流类对象cin上。 1cin &gt;&gt; 表达式 &gt;&gt; 表达式... 提取符可以连续写多个，每个后面跟一个表达式，该表达式通常是用于存放输入值的变量。例如： 123int a, b;cin &gt;&gt; a &gt;&gt; b; 常用的I/O流类库操纵符 例： 1234567#include &lt;iostream&gt;#include &lt;iomanip&gt;using namespace std;int main() &#123; cout &lt;&lt; setw(5) &lt;&lt; setprecision(3) &lt;&lt; 3.1415; return 0;&#125; 输出 3.14 4 算法基本控制结构4.1 if 语句12345678910111213141516171819//判断是不是闰年#include &lt;iostream&gt;using namespace std;int main()&#123; int year; bool isLeapYear; cout &lt;&lt; "Enter the year: "; cin &gt;&gt; year; isLeapYear = ((year % 4 == 0 &amp;&amp; year % 100 != 0) || (year % 400 == 0)); if (isLeapYear) cout &lt;&lt; year &lt;&lt; " is a leap year" &lt;&lt; endl; else cout &lt;&lt; year &lt;&lt; " is not a leap year" &lt;&lt; endl; return 0;&#125; 注意：如果if else 语句里面还有if else语句，最好有{}来确定层次关系，否则在省略else情况下会出错。 4.2 switch 语句1234567891011121314151617181920212223242526//判断星期几#include &lt;iostream&gt;using namespace std;int main()&#123; int day; cin &gt;&gt; day; switch (day)&#123; case 0: cout &lt;&lt; "星期天" &lt;&lt; endl; break; case 1: cout &lt;&lt; "星期一" &lt;&lt; endl; break; case 2: cout &lt;&lt; "星期二" &lt;&lt; endl; break; case 3: cout &lt;&lt; "星期三" &lt;&lt; endl; break; case 4: cout &lt;&lt; "星期四" &lt;&lt; endl; break; case 5: cout &lt;&lt; "星期五" &lt;&lt; endl; break; case 6: cout &lt;&lt; "星期六" &lt;&lt; endl; break; &#125; return 0;&#125; 4.3 while 语句12345678910111213//计算1加到10#include &lt;iostream&gt;using namespace std;int main()&#123; int i = 1, sum = 0; while (i &lt;= 10)&#123; sum += i; i++; &#125; cout &lt;&lt; "sum = " &lt;&lt; sum &lt;&lt; endl; return 0;&#125; 4.4 do while 语句12345678910111213//计算1加到10#include &lt;iostream&gt;using namespace std;int main()&#123; int i = 1, sum = 0; do&#123; sum += i; i++; &#125;while (i &lt;= 10); cout &lt;&lt; "sum = " &lt;&lt; sum &lt;&lt; endl; return 0;&#125; 4.5 for 语句123456789101112131415//求一个整数所有因子#include &lt;iostream&gt;using namespace std;int main()&#123; int n; cout &lt;&lt; "Enter a positive integer: "; cin &gt;&gt; n; cout &lt;&lt; "Number " &lt;&lt; n &lt;&lt; " Factors "; for (int k=1; k&lt;=n; k++) if (n%k==0) cout &lt;&lt; k &lt;&lt; " "; cout &lt;&lt; endl; return 0;&#125;]]></content>
      <categories>
        <category>语言学习</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ORB_SLAM2地图保存与加载（2）]]></title>
    <url>%2F2019%2F08%2F27%2FORB_SLAM2%E5%9C%B0%E5%9B%BE%E4%BF%9D%E5%AD%98%E4%B8%8E%E5%8A%A0%E8%BD%BD%EF%BC%882%EF%BC%89%2F</url>
    <content type="text"><![CDATA[本文记录了ORB_SLAM2中地图加载的过程。参考博客：https://blog.csdn.net/qq_34254510/article/details/79969046http://www.cnblogs.com/mafuqiang/p/6972841.htmlhttps://blog.csdn.net/felaim/article/details/79667635https://blog.csdn.net/u014709760/article/details/86319090 2 地图加载2.1 源码修改地图加载部分需要修改的较多，所以按所需修改的文件来进行说明。 （1）Map相关文件修改在Map.h文件中声明地图加载函数、地图点加载函数和关键帧加载函数： 1234//加载地图信息 void Load(const string &amp;filename,SystemSetting* mySystemSetting); MapPoint* LoadMapPoint(ifstream &amp;f); KeyFrame* LoadKeyFrame(ifstream &amp;f,SystemSetting* mySystemSetting); Map.h中需要加入SystemSetting.h： 1234#include "SystemSetting.h"### 还要添加class SystemSetting; 在Map.cc文件中进行相应实现： 地图加载函数 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293//地图加载函数void Map::Load ( const string &amp;filename, SystemSetting* mySystemSetting)&#123; cerr &lt;&lt; "Map.cc :: Map reading from:"&lt;&lt;filename&lt;&lt;endl; ifstream f; f.open( filename.c_str() ); // Same as the sequence that we save the file, we first read the number of MapPoints. unsigned long int nMapPoints; f.read((char*)&amp;nMapPoints, sizeof(nMapPoints)); // Then read MapPoints one after another, and add them into the map cerr&lt;&lt;"Map.cc :: The number of MapPoints:"&lt;&lt;nMapPoints&lt;&lt;endl; for ( unsigned int i = 0; i &lt; nMapPoints; i ++ ) &#123; MapPoint* mp = LoadMapPoint(f); AddMapPoint(mp); &#125; // Get all MapPoints std::vector&lt;MapPoint*&gt; vmp = GetAllMapPoints(); // Read the number of KeyFrames unsigned long int nKeyFrames; f.read((char*)&amp;nKeyFrames, sizeof(nKeyFrames)); cerr&lt;&lt;"Map.cc :: The number of KeyFrames:"&lt;&lt;nKeyFrames&lt;&lt;endl; // Then read KeyFrames one after another, and add them into the map vector&lt;KeyFrame*&gt;kf_by_order; for( unsigned int i = 0; i &lt; nKeyFrames; i ++ ) &#123; KeyFrame* kf = LoadKeyFrame(f, mySystemSetting); AddKeyFrame(kf); kf_by_order.push_back(kf); &#125; cerr&lt;&lt;"Map.cc :: Max KeyFrame ID is: " &lt;&lt; mnMaxKFid &lt;&lt; ", and I set mnId to this number" &lt;&lt;endl; cerr&lt;&lt;"Map.cc :: KeyFrame Load OVER!"&lt;&lt;endl; // Read Spanning Tree(open loop trajectory) map&lt;unsigned long int, KeyFrame*&gt; kf_by_id; for ( auto kf: mspKeyFrames ) kf_by_id[kf-&gt;mnId] = kf; cerr&lt;&lt;"Map.cc :: Start Load The Parent!"&lt;&lt;endl; for( auto kf: kf_by_order ) &#123; // Read parent_id of current KeyFrame. unsigned long int parent_id; f.read((char*)&amp;parent_id, sizeof(parent_id)); // Add parent KeyFrame to current KeyFrame. // cout&lt;&lt;"Map::Load : Add parent KeyFrame to current KeyFrame"&lt;&lt;endl; if ( parent_id != ULONG_MAX ) kf-&gt;ChangeParent(kf_by_id[parent_id]); // Read covisibility graphs. // Read the number of Connected KeyFrames of current KeyFrame. unsigned long int nb_con; f.read((char*)&amp;nb_con, sizeof(nb_con)); // Read id and weight of Connected KeyFrames of current KeyFrame, // and add Connected KeyFrames into covisibility graph. // cout&lt;&lt;"Map::Load : Read id and weight of Connected KeyFrames"&lt;&lt;endl; for ( unsigned long int i = 0; i &lt; nb_con; i ++ ) &#123; unsigned long int id; int weight; f.read((char*)&amp;id, sizeof(id)); f.read((char*)&amp;weight, sizeof(weight)); kf-&gt;AddConnection(kf_by_id[id],weight); &#125; &#125; cerr&lt;&lt;"Map.cc :: Parent Load OVER!"&lt;&lt;endl; for ( auto mp: vmp ) &#123; // cout &lt;&lt; "Now mp = "&lt;&lt; mp &lt;&lt; endl; if(mp) &#123; // cout &lt;&lt; "compute for mp = "&lt;&lt; mp &lt;&lt; endl; mp-&gt;ComputeDistinctiveDescriptors(); // cout &lt;&lt; "Computed Distinctive Descriptors." &lt;&lt; endl; mp-&gt;UpdateNormalAndDepth(); // cout &lt;&lt; "Updated Normal And Depth." &lt;&lt; endl; &#125; &#125; f.close(); cerr&lt;&lt;"Map.cc :: Load IS OVER!"&lt;&lt;endl; return;&#125; 其过程就是根据保存的顺序依次加载地图点的数目、地图点、关键帧的数目、关键帧、生长树和关联关系。 地图点加载函数： 123456789101112131415161718MapPoint* Map::LoadMapPoint( ifstream &amp;f )&#123; // Position and Orientation of the MapPoints. cv::Mat Position(3,1,CV_32F); long unsigned int id; f.read((char*)&amp;id, sizeof(id)); f.read((char*)&amp;Position.at&lt;float&gt;(0), sizeof(float)); f.read((char*)&amp;Position.at&lt;float&gt;(1), sizeof(float)); f.read((char*)&amp;Position.at&lt;float&gt;(2), sizeof(float)); // Initialize a MapPoint, and set its id and Position. MapPoint* mp = new MapPoint(Position, this ); mp-&gt;mnId = id; mp-&gt;SetWorldPos( Position ); return mp;&#125; 关键帧加载函数： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485KeyFrame* Map::LoadKeyFrame( ifstream &amp;f, SystemSetting* mySystemSetting )&#123; InitKeyFrame initkf(*mySystemSetting); // Read ID and TimeStamp of each KeyFrame. f.read((char*)&amp;initkf.nId, sizeof(initkf.nId)); f.read((char*)&amp;initkf.TimeStamp, sizeof(double)); // Read position and quaternion cv::Mat T = cv::Mat::zeros(4,4,CV_32F); std::vector&lt;float&gt; Quat(4); //Quat.reserve(4); for ( int i = 0; i &lt; 4; i ++ ) f.read((char*)&amp;Quat[i],sizeof(float)); cv::Mat R = Converter::toCvMat(Quat); for ( int i = 0; i &lt; 3; i ++ ) f.read((char*)&amp;T.at&lt;float&gt;(i,3),sizeof(float)); for ( int i = 0; i &lt; 3; i ++ ) for ( int j = 0; j &lt; 3; j ++ ) T.at&lt;float&gt;(i,j) = R.at&lt;float&gt;(i,j); T.at&lt;float&gt;(3,3) = 1; // Read feature point number of current Key Frame f.read((char*)&amp;initkf.N, sizeof(initkf.N)); initkf.vKps.reserve(initkf.N); initkf.Descriptors.create(initkf.N, 32, CV_8UC1); vector&lt;float&gt;KeypointDepth; std::vector&lt;MapPoint*&gt; vpMapPoints; vpMapPoints = vector&lt;MapPoint*&gt;(initkf.N,static_cast&lt;MapPoint*&gt;(NULL)); // Read Keypoints and descriptors of current KeyFrame std::vector&lt;MapPoint*&gt; vmp = GetAllMapPoints(); for(int i = 0; i &lt; initkf.N; i ++ ) &#123; cv::KeyPoint kp; f.read((char*)&amp;kp.pt.x, sizeof(kp.pt.x)); f.read((char*)&amp;kp.pt.y, sizeof(kp.pt.y)); f.read((char*)&amp;kp.size, sizeof(kp.size)); f.read((char*)&amp;kp.angle,sizeof(kp.angle)); f.read((char*)&amp;kp.response, sizeof(kp.response)); f.read((char*)&amp;kp.octave, sizeof(kp.octave)); initkf.vKps.push_back(kp); // Read descriptors of keypoints f.read((char*)&amp;initkf.Descriptors.cols, sizeof(initkf.Descriptors.cols)); // for ( int j = 0; j &lt; 32; j ++ ) // Since initkf.Descriptors.cols is always 32, for loop may also write like this. for ( int j = 0; j &lt; initkf.Descriptors.cols; j ++ ) f.read((char*)&amp;initkf.Descriptors.at&lt;unsigned char&gt;(i,j),sizeof(char)); // Read the mapping from keypoints to MapPoints. unsigned long int mpidx; f.read((char*)&amp;mpidx, sizeof(mpidx)); // Look up from vmp, which contains all MapPoints, MapPoint of current KeyFrame, and then insert in vpMapPoints. if( mpidx == ULONG_MAX ) vpMapPoints[i] = NULL; else vpMapPoints[i] = vmp[mpidx]; &#125; initkf.vRight = vector&lt;float&gt;(initkf.N,-1); initkf.vDepth = vector&lt;float&gt;(initkf.N,-1); //initkf.vDepth = KeypointDepth; initkf.UndistortKeyPoints(); initkf.AssignFeaturesToGrid(); // Use initkf to initialize a KeyFrame and set parameters KeyFrame* kf = new KeyFrame( initkf, this, NULL, vpMapPoints ); kf-&gt;mnId = initkf.nId; kf-&gt;SetPose(T); kf-&gt;ComputeBoW(); for ( int i = 0; i &lt; initkf.N; i ++ ) &#123; if ( vpMapPoints[i] ) &#123; vpMapPoints[i]-&gt;AddObservation(kf,i); if( !vpMapPoints[i]-&gt;GetReferenceKeyFrame()) vpMapPoints[i]-&gt;SetReferenceKeyFrame(kf); &#125; &#125; return kf;&#125; （2）MapPoint相关文件修改由于在加载地图时我们只有Position以及当前的Map，所以需要重新定义一种MapPoint类的构造函数以满足要求。 在MapPoint.h文件中添加如下构造函数： 123MapPoint(const cv::Mat &amp;Pos,Map* pMap);KeyFrame* SetReferenceKeyFrame(KeyFrame* RFKF); 在MapPoint.cc文件中实现该构造函数： 123456789101112MapPoint::MapPoint(const cv::Mat &amp;Pos, Map* pMap): mnFirstKFid(0), mnFirstFrame(0), nObs(0), mnTrackReferenceForFrame(0), mnLastFrameSeen(0), mnBALocalForKF(0), mnFuseCandidateForKF(0), mnLoopPointForKF(0), mnCorrectedByKF(0), mnCorrectedReference(0), mnBAGlobalForKF(0), mpRefKF(static_cast&lt;KeyFrame*&gt;(NULL)), mnVisible(1), mnFound(1), mbBad(false), mpReplaced(static_cast&lt;MapPoint*&gt;(NULL)), mfMinDistance(0), mfMaxDistance(0), mpMap(pMap) &#123; Pos.copyTo(mWorldPos); mNormalVector = cv::Mat::zeros(3,1,CV_32F); // MapPoints can be created from Tracking and Local Mapping. This mutex avoid conflicts with id. unique_lock&lt;mutex&gt; lock(mpMap-&gt;mMutexPointCreation); mnId=nNextId++; &#125; 此外，还需要添加如下函数： 1234KeyFrame* MapPoint::SetReferenceKeyFrame(KeyFrame* RFKF)&#123; return mpRefKF = RFKF;&#125; （3）KeyFrame相关文件修改与MapPoint文件相同，KeyFrame文件也要做相关修改。 在KeyFrame.h文件中添加如下构造函数： 1KeyFrame(InitKeyFrame &amp;initkf,Map* pMap,KeyFrameDatabase* pKFDB,vector&lt;MapPoint*&gt;&amp; vpMapPoints); 不要忘记在KeyFrame.h中添加相应头文件和命名空间中的类声明 12345678#include "MapPoint.h"#include "Thirdparty/DBoW2/DBoW2/BowVector.h"#include "Thirdparty/DBoW2/DBoW2/FeatureVector.h"#include "ORBVocabulary.h"#include "ORBextractor.h"#include "Frame.h"#include "KeyFrameDatabase.h"#include "InitKeyFrame.h" 123456789class Map;class MapPoint;class Frame;class KeyFrameDatabase;class InitKeyFrame;class KeyFrame&#123;public: 在KeyFrame.cc文件中实现该构造函数： 123456789101112131415161718KeyFrame::KeyFrame(InitKeyFrame &amp;initkf, Map *pMap, KeyFrameDatabase *pKFDB, vector&lt;MapPoint*&gt; &amp;vpMapPoints): mnFrameId(0), mTimeStamp(initkf.TimeStamp), mnGridCols(FRAME_GRID_COLS), mnGridRows(FRAME_GRID_ROWS), mfGridElementWidthInv(initkf.fGridElementWidthInv), mfGridElementHeightInv(initkf.fGridElementHeightInv), mnTrackReferenceForFrame(0), mnFuseTargetForKF(0), mnBALocalForKF(0), mnBAFixedForKF(0), mnLoopQuery(0), mnLoopWords(0), mnRelocQuery(0), mnRelocWords(0), mnBAGlobalForKF(0), fx(initkf.fx), fy(initkf.fy), cx(initkf.cx), cy(initkf.cy), invfx(initkf.invfx), invfy(initkf.invfy), mbf(initkf.bf), mb(initkf.b), mThDepth(initkf.ThDepth), N(initkf.N), mvKeys(initkf.vKps), mvKeysUn(initkf.vKpsUn), mvuRight(initkf.vRight), mvDepth(initkf.vDepth), mDescriptors(initkf.Descriptors.clone()), mBowVec(initkf.BowVec), mFeatVec(initkf.FeatVec), mnScaleLevels(initkf.nScaleLevels), mfScaleFactor(initkf.fScaleFactor), mfLogScaleFactor(initkf.fLogScaleFactor), mvScaleFactors(initkf.vScaleFactors), mvLevelSigma2(initkf.vLevelSigma2),mvInvLevelSigma2(initkf.vInvLevelSigma2), mnMinX(initkf.nMinX), mnMinY(initkf.nMinY), mnMaxX(initkf.nMaxX), mnMaxY(initkf.nMaxY), mK(initkf.K), mvpMapPoints(vpMapPoints), mpKeyFrameDB(pKFDB), mpORBvocabulary(initkf.pVocabulary), mbFirstConnection(true), mpParent(NULL), mbNotErase(false), mbToBeErased(false), mbBad(false), mHalfBaseline(initkf.b/2), mpMap(pMap) &#123; mnId = nNextId ++; &#125; （4）SystemSetting和InitKeyFrame相关文件在上面的函数中我们用到了SystemSetting类和InitKeyFrame类。其中SystemSetting类用于读取参数文件中的相关参数，InitKeyFrame类用于进行关键帧初始化。其实现过程如下： 创建 SystemSetting.h 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354#ifndef SYSTEMSETTING_H#define SYSTEMSETTING_H#include&lt;string&gt;#include"ORBVocabulary.h"#include&lt;opencv2/opencv.hpp&gt;namespace ORB_SLAM2 &#123; class SystemSetting&#123; public: SystemSetting(ORBVocabulary* pVoc); bool LoadSystemSetting(const std::string strSettingPath); public: ORBVocabulary* pVocavulary; //相机参数 float width; float height; float fx; float fy; float cx; float cy; float invfx; float invfy; float bf; float b; float fps; cv::Mat K; cv::Mat DistCoef; bool initialized; //相机 RGB 参数 int nRGB; //ORB特征参数 int nFeatures; float fScaleFactor; int nLevels; float fIniThFAST; float fMinThFAST; //其他参数 float ThDepth = -1; float DepthMapFactor = -1; &#125;; &#125;//namespace ORB_SLAM2#endif //SystemSetting 创建 SystemSetting.cc的函数具体实现： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788#include&lt;iostream&gt;#include"SystemSetting.h"using namespace std;namespace ORB_SLAM2 &#123; SystemSetting::SystemSetting(ORBVocabulary* pVoc):pVocavulary(pVoc) &#123; &#125; bool SystemSetting::LoadSystemSetting(const std::string strSettingPath) &#123; cout&lt;&lt;endl&lt;&lt;"Loading System Parameters form:"&lt;&lt;strSettingPath&lt;&lt;endl; cv::FileStorage fSettings(strSettingPath, cv::FileStorage::READ); width = fSettings["Camera.width"]; height = fSettings["Camera.height"]; fx = fSettings["Camera.fx"]; fy = fSettings["Camera.fy"]; cx = fSettings["Camera.cx"]; cy = fSettings["Camera.cy"]; cv::Mat tmpK = cv::Mat::eye(3,3,CV_32F); tmpK.at&lt;float&gt;(0,0) = fx; tmpK.at&lt;float&gt;(1,1) = fy; tmpK.at&lt;float&gt;(0,2) = cx; tmpK.at&lt;float&gt;(1,2) = cy; tmpK.copyTo(K); cv::Mat tmpDistCoef(4,1,CV_32F); tmpDistCoef.at&lt;float&gt;(0) = fSettings["Camera.k1"]; tmpDistCoef.at&lt;float&gt;(1) = fSettings["Camera.k2"]; tmpDistCoef.at&lt;float&gt;(2) = fSettings["Camera.p1"]; tmpDistCoef.at&lt;float&gt;(3) = fSettings["Camera.p2"]; const float k3 = fSettings["Camera.k3"]; if( k3!=0 ) &#123; tmpDistCoef.resize(5); tmpDistCoef.at&lt;float&gt;(4) = k3; &#125; tmpDistCoef.copyTo( DistCoef ); bf = fSettings["Camera.bf"]; fps= fSettings["Camera.fps"]; invfx = 1.0f/fx; invfy = 1.0f/fy; b = bf /fx; initialized = true; cout&lt;&lt;"- size:"&lt;&lt;width&lt;&lt;"x"&lt;&lt;height&lt;&lt;endl; cout&lt;&lt;"- fx:" &lt;&lt;fx&lt;&lt;endl; cout &lt;&lt; "- fy: " &lt;&lt; fy &lt;&lt; endl; cout &lt;&lt; "- cx: " &lt;&lt; cx &lt;&lt; endl; cout &lt;&lt; "- cy: " &lt;&lt; cy &lt;&lt; endl; cout &lt;&lt; "- k1: " &lt;&lt; DistCoef.at&lt;float&gt;(0) &lt;&lt; endl; cout &lt;&lt; "- k2: " &lt;&lt; DistCoef.at&lt;float&gt;(1) &lt;&lt; endl; if(DistCoef.rows==5) cout &lt;&lt; "- k3: " &lt;&lt; DistCoef.at&lt;float&gt;(4) &lt;&lt; endl; cout &lt;&lt; "- p1: " &lt;&lt; DistCoef.at&lt;float&gt;(2) &lt;&lt; endl; cout &lt;&lt; "- p2: " &lt;&lt; DistCoef.at&lt;float&gt;(3) &lt;&lt; endl; cout &lt;&lt; "- bf: " &lt;&lt; bf &lt;&lt; endl; //Load RGB parameter nRGB = fSettings["Camera.RGB"]; //Load ORB feature parameters nFeatures = fSettings["ORBextractor.nFeatures"]; fScaleFactor = fSettings["ORBextractor.scaleFactor"]; nLevels = fSettings["ORBextractor.nLevels"]; fIniThFAST = fSettings["ORBextractor.iniThFAST"]; fMinThFAST = fSettings["ORBextractor.minThFAST"]; cout &lt;&lt; endl &lt;&lt; "ORB Extractor Parameters: " &lt;&lt; endl; cout &lt;&lt; "- Number of Features: " &lt;&lt; nFeatures &lt;&lt; endl; cout &lt;&lt; "- Scale Levels: " &lt;&lt; nLevels &lt;&lt; endl; cout &lt;&lt; "- Scale Factor: " &lt;&lt; fScaleFactor &lt;&lt; endl; cout &lt;&lt; "- Initial Fast Threshold: " &lt;&lt; fIniThFAST &lt;&lt; endl; cout &lt;&lt; "- Minimum Fast Threshold: " &lt;&lt; fMinThFAST &lt;&lt; endl; //Load others parameters, if the sensor is MONOCULAR, the parameters is zero; //ThDepth = fSettings["ThDepth"]; //DepthMapFactor = fSettings["DepthMapFactor"]; fSettings.release(); return true; &#125;&#125; 创建 InitKeyFrame.h文件 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182#ifndef INITKEYFRAME_H#define INITKEYFRAME_H#include "Thirdparty/DBoW2/DBoW2/BowVector.h"#include "Thirdparty/DBoW2/DBoW2/FeatureVector.h"#include "SystemSetting.h"#include &lt;opencv2/opencv.hpp&gt;#include "ORBVocabulary.h"#include "KeyFrameDatabase.h"//#include "MapPoints.h"namespace ORB_SLAM2&#123;#define FRAME_GRID_ROWS 48#define FRAME_GRID_COLS 64class SystemSetting;class KeyFrameDatabase;//class ORBVocabulary;class InitKeyFrame&#123;public: InitKeyFrame(SystemSetting &amp;SS); void UndistortKeyPoints(); bool PosInGrid(const cv::KeyPoint&amp; kp, int &amp;posX, int &amp;posY); void AssignFeaturesToGrid();public: ORBVocabulary* pVocabulary; //KeyFrameDatabase* pKeyFrameDatabase; long unsigned int nId; double TimeStamp; float fGridElementWidthInv; float fGridElementHeightInv; std::vector&lt;std::size_t&gt; vGrid[FRAME_GRID_COLS][FRAME_GRID_ROWS]; float fx; float fy; float cx; float cy; float invfx; float invfy; float bf; float b; float ThDepth; int N; std::vector&lt;cv::KeyPoint&gt; vKps; std::vector&lt;cv::KeyPoint&gt; vKpsUn; cv::Mat Descriptors; //it's zero for mono std::vector&lt;float&gt; vRight; std::vector&lt;float&gt; vDepth; DBoW2::BowVector BowVec; DBoW2::FeatureVector FeatVec; int nScaleLevels; float fScaleFactor; float fLogScaleFactor; std::vector&lt;float&gt; vScaleFactors; std::vector&lt;float&gt; vLevelSigma2; std::vector&lt;float&gt; vInvLevelSigma2; std::vector&lt;float&gt; vInvScaleFactors; int nMinX; int nMinY; int nMaxX; int nMaxY; cv::Mat K; cv::Mat DistCoef; &#125;;&#125; //namespace ORB_SLAM2#endif //INITKEYFRAME_H 创建 InitKeyFrame.cc的函数具体实现： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136#include "InitKeyFrame.h"#include &lt;opencv2/opencv.hpp&gt;#include "SystemSetting.h"namespace ORB_SLAM2&#123;InitKeyFrame::InitKeyFrame(SystemSetting &amp;SS):pVocabulary(SS.pVocavulary)//, pKeyFrameDatabase(SS.pKeyFrameDatabase)&#123; fx = SS.fx; fy = SS.fy; cx = SS.cx; cy = SS.cy; invfx = SS.invfx; invfy = SS.invfy; bf = SS.bf; b = SS.b; ThDepth = SS.ThDepth; nScaleLevels = SS.nLevels; fScaleFactor = SS.fScaleFactor; fLogScaleFactor = log(SS.fScaleFactor); vScaleFactors.resize(nScaleLevels); vLevelSigma2.resize(nScaleLevels); vScaleFactors[0] = 1.0f; vLevelSigma2[0] = 1.0f; for ( int i = 1; i &lt; nScaleLevels; i ++ ) &#123; vScaleFactors[i] = vScaleFactors[i-1]*fScaleFactor; vLevelSigma2[i] = vScaleFactors[i]*vScaleFactors[i]; &#125; vInvScaleFactors.resize(nScaleLevels); vInvLevelSigma2.resize(nScaleLevels); for ( int i = 0; i &lt; nScaleLevels; i ++ ) &#123; vInvScaleFactors[i] = 1.0f/vScaleFactors[i]; vInvLevelSigma2[i] = 1.0f/vLevelSigma2[i]; &#125; K = SS.K; DistCoef = SS.DistCoef; if( SS.DistCoef.at&lt;float&gt;(0)!=0.0) &#123; cv::Mat mat(4,2,CV_32F); mat.at&lt;float&gt;(0,0) = 0.0; mat.at&lt;float&gt;(0,1) = 0.0; mat.at&lt;float&gt;(1,0) = SS.width; mat.at&lt;float&gt;(1,1) = 0.0; mat.at&lt;float&gt;(2,0) = 0.0; mat.at&lt;float&gt;(2,1) = SS.height; mat.at&lt;float&gt;(3,0) = SS.width; mat.at&lt;float&gt;(3,1) = SS.height; mat = mat.reshape(2); cv::undistortPoints(mat, mat, SS.K, SS.DistCoef, cv::Mat(), SS.K); mat = mat.reshape(1); nMinX = min(mat.at&lt;float&gt;(0,0), mat.at&lt;float&gt;(2,0)); nMaxX = max(mat.at&lt;float&gt;(1,0), mat.at&lt;float&gt;(3,0)); nMinY = min(mat.at&lt;float&gt;(0,1), mat.at&lt;float&gt;(1,1)); nMaxY = max(mat.at&lt;float&gt;(2,1), mat.at&lt;float&gt;(3,1)); &#125; else &#123; nMinX = 0.0f; nMaxX = SS.width; nMinY = 0.0f; nMaxY = SS.height; &#125; fGridElementWidthInv=static_cast&lt;float&gt;(FRAME_GRID_COLS)/(nMaxX-nMinX); fGridElementHeightInv=static_cast&lt;float&gt;(FRAME_GRID_ROWS)/(nMaxY-nMinY); &#125;void InitKeyFrame::UndistortKeyPoints()&#123; if( DistCoef.at&lt;float&gt;(0) == 0.0) &#123; vKpsUn = vKps; return; &#125; cv::Mat mat(N,2,CV_32F); for ( int i = 0; i &lt; N; i ++ ) &#123; mat.at&lt;float&gt;(i,0) = vKps[i].pt.x; mat.at&lt;float&gt;(i,1) = vKps[i].pt.y; &#125; mat = mat.reshape(2); cv::undistortPoints(mat, mat, K, DistCoef, cv::Mat(), K ); mat = mat.reshape(1); vKpsUn.resize(N); for( int i = 0; i &lt; N; i ++ ) &#123; cv::KeyPoint kp = vKps[i]; kp.pt.x = mat.at&lt;float&gt;(i,0); kp.pt.y = mat.at&lt;float&gt;(i,1); vKpsUn[i] = kp; &#125;&#125;void InitKeyFrame::AssignFeaturesToGrid()&#123; int nReserve = 0.5f*N/(FRAME_GRID_COLS*FRAME_GRID_ROWS); for ( unsigned int i = 0; i &lt; FRAME_GRID_COLS; i ++ ) &#123; for ( unsigned int j = 0; j &lt; FRAME_GRID_ROWS; j ++) vGrid[i][j].reserve(nReserve); &#125; for ( int i = 0; i &lt; N; i ++ ) &#123; const cv::KeyPoint&amp; kp = vKpsUn[i]; int nGridPosX, nGridPosY; if( PosInGrid(kp, nGridPosX, nGridPosY)) vGrid[nGridPosX][nGridPosY].push_back(i); &#125;&#125;bool InitKeyFrame::PosInGrid(const cv::KeyPoint &amp;kp, int &amp;posX, int &amp;posY)&#123; posX = round((kp.pt.x-nMinX)*fGridElementWidthInv); posY = round((kp.pt.y-nMinY)*fGridElementHeightInv); if(posX&lt;0 || posX&gt;=FRAME_GRID_COLS ||posY&lt;0 || posY&gt;=FRAME_GRID_ROWS) return false; return true;&#125;&#125; （5）System相关文件的修改在System.h中添加函数定义： 1void LoadMap(const string &amp;filename); 添加声明： 1std::string mySettingFile; 在对应的System.cc中添加了定义 12345678//地图加载void System::LoadMap(const string &amp;filename)&#123; SystemSetting* mySystemSetting = new SystemSetting(mpVocabulary); mySystemSetting-&gt;LoadSystemSetting(mySettingFile); mpMap-&gt;Load(filename,mySystemSetting);&#125; 同时在构造函数函数中对mySettingFile成员变量赋值 1mySettingFile = strSettingsFile; //放在System::System里的check settings file 后面 2.2 测试修改CMakeLists.txt 文件 123456789101112131415161718192021222324#在add_library 中加入 src/InitkeyFrame.cc src/SystemSetting.ccadd_library($&#123;PROJECT_NAME&#125; SHAREDsrc/System.ccsrc/Tracking.ccsrc/LocalMapping.ccsrc/LoopClosing.ccsrc/ORBextractor.ccsrc/ORBmatcher.ccsrc/FrameDrawer.ccsrc/Converter.ccsrc/MapPoint.ccsrc/KeyFrame.ccsrc/Map.ccsrc/MapDrawer.ccsrc/Optimizer.ccsrc/PnPsolver.ccsrc/Frame.ccsrc/KeyFrameDatabase.ccsrc/Sim3Solver.ccsrc/Initializer.ccsrc/Viewer.ccsrc/InitKeyFrame.ccsrc/SystemSetting.cc) 一定要注意大小写！！！！网上写的是src/InitkeyFrame.cc，报错找了半天问题。 修改/ORB_SLAM2/Examples/ROS/ORB_SLAM2/src/ros_rgbd.cc文件中的main函数中加入如下语句： 1SLAM.LoadMap("/home/zj224/ORB_SLAM2/Examples/ROS/ORB_SLAM2/map.bin");//load the map 加在ros::spin()之前 重新编译ORB_SLAM2库 123456789cd ~/ORB_SLAM2chmod +x build.sh./build.sh source /opt/ros/kinetic/setup.shsource ~/.bashrcchmod +x build_ros.sh./build_ros.sh### 若出错，参考 ORB_slam实现 测试 12345678roscore### 新建终端roslaunch kinect2_bridge kinect2_bridge.launch### 新建终端cd ~/ORB_SLAM2/Examples/ROS/ORB_SLAM2rosrun ORB_SLAM2 RGBD /home/zj224/ORB_SLAM2/Vocabulary/ORBvoc.txt /home/zj224/ORB_SLAM2/Examples/RGB-D/kinect2.yaml### 就能看到加载的地图了 TODO加载功能也只是单纯地实现了地图加载，重定位、导航等问题有待进一步完善。这两天做地图保存和加载功能的实现，我发觉应该先学习ORB_SLAM2整个库的逻辑结构和代码解读，而不是直接按照博客的东西一顿忙改，功能实现了，但是不懂内部是不行的。接下来会先学习这个库，再去研究进一步的功能。]]></content>
      <categories>
        <category>slam</category>
      </categories>
      <tags>
        <tag>slam实现</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ORB_SLAM2地图保存与加载（1）]]></title>
    <url>%2F2019%2F08%2F26%2FORB_SLAM2%E5%9C%B0%E5%9B%BE%E4%BF%9D%E5%AD%98%E4%B8%8E%E5%8A%A0%E8%BD%BD%EF%BC%881%EF%BC%89%2F</url>
    <content type="text"><![CDATA[本文记录了ORB_SLAM2中地图保存的过程。参考博客：https://blog.csdn.net/qq_34254510/article/details/79969046http://www.cnblogs.com/mafuqiang/p/6972841.htmlhttps://blog.csdn.net/felaim/article/details/79667635https://blog.csdn.net/u014709760/article/details/86319090 1 地图保存1.1 地图元素分析所谓地图保存，就是保存地图“Map”中的各个元素，以及它们之间的关系，凡是跟踪过程中需要用到的东西自然也就是需要保存的对象。地图主要包含关键帧、3D地图点、BoW向量、共视图、生长树等，在跟踪过程中有三种跟踪模型和局部地图跟踪等过程，局部地图跟踪需要用到3D地图点、共视关系等元素，参考帧模型需要用到关键帧的BoW向量，重定位需要用到BoW向量、3D点等。所以基本上述元素都需要保存。 另一方面，关键帧也是一个抽象的概念（一个类），我们看看具体包含什么（其实都在关键帧类里面了），关键帧是从普通帧来的，所以得到视频帧后首先需要做的就是检测特征点，计算描述符，还有当前帧的相机位姿。成为关键帧之后需要有对应的ID编号，以及特征点进行三角化之后的3D地图点等。 关于3D地图点需要保存的就只有世界坐标了，至于其它的关联关系可以从关键帧获得。需要单独说的是在关键帧类中包含了特征点和描述符，所以BoW向量是不需要保存的（也没办法保存），只需要在加载了关键帧之后利用特征描述符重新计算即可。 所以现在需要保存的东西包括关键帧、3D地图点、共视图、生长树。 1.2 源码修改SLAM对地图维护的操作均在Map.cc这个函数类中，所以要保存地图，我们需要在这个文件中添加相应代码。 （1）修改Map.h头文件在/ORB_SLAM2/include/Map.h文件中的Map类中添加如下函数： 在Map.h的头文件中要添加Converter.h 123456789public: //保存地图信息 void Save(const string &amp;filename);protected: //保存地图点和关键帧 void SaveMapPoint(ofstream &amp;f,MapPoint* mp); void SaveKeyFrame(ofstream &amp;f,KeyFrame* kf); std::map&lt;MapPoint*, unsigned long int&gt; mmpnMapPointsIdx; void GetMapPointsIdx(); （2）修改Map.cc文件在/ORB_SLAM2/src/Map.cc文件中添加第一步中函数的实现。 Save()函数的实现过程： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162//保存地图信息void Map::Save ( const string&amp; filename )&#123; //Print the information of the saving map cerr&lt;&lt;"Map.cc :: Map Saving to "&lt;&lt;filename &lt;&lt;endl; ofstream f; f.open(filename.c_str(), ios_base::out|ios::binary); //Number of MapPoints unsigned long int nMapPoints = mspMapPoints.size(); f.write((char*)&amp;nMapPoints, sizeof(nMapPoints) ); //Save MapPoint sequentially for ( auto mp: mspMapPoints )&#123; //Save MapPoint SaveMapPoint( f, mp ); // cerr &lt;&lt; "Map.cc :: Saving map point number: " &lt;&lt; mp-&gt;mnId &lt;&lt; endl; &#125; //Print The number of MapPoints cerr &lt;&lt; "Map.cc :: The number of MapPoints is :"&lt;&lt;mspMapPoints.size()&lt;&lt;endl; //Grab the index of each MapPoint, count from 0, in which we initialized mmpnMapPointsIdx GetMapPointsIdx(); //Print the number of KeyFrames cerr &lt;&lt;"Map.cc :: The number of KeyFrames:"&lt;&lt;mspKeyFrames.size()&lt;&lt;endl; //Number of KeyFrames unsigned long int nKeyFrames = mspKeyFrames.size(); f.write((char*)&amp;nKeyFrames, sizeof(nKeyFrames)); //Save KeyFrames sequentially for ( auto kf: mspKeyFrames ) SaveKeyFrame( f, kf ); for (auto kf:mspKeyFrames ) &#123; //Get parent of current KeyFrame and save the ID of this parent KeyFrame* parent = kf-&gt;GetParent(); unsigned long int parent_id = ULONG_MAX; if ( parent ) parent_id = parent-&gt;mnId; f.write((char*)&amp;parent_id, sizeof(parent_id)); //Get the size of the Connected KeyFrames of the current KeyFrames //and then save the ID and weight of the Connected KeyFrames unsigned long int nb_con = kf-&gt;GetConnectedKeyFrames().size(); f.write((char*)&amp;nb_con, sizeof(nb_con)); for ( auto ckf: kf-&gt;GetConnectedKeyFrames()) &#123; int weight = kf-&gt;GetWeight(ckf); f.write((char*)&amp;ckf-&gt;mnId, sizeof(ckf-&gt;mnId)); f.write((char*)&amp;weight, sizeof(weight)); &#125; &#125; // Save last Frame ID // SaveFrameID(f); f.close(); cerr&lt;&lt;"Map.cc :: Map Saving Finished!"&lt;&lt;endl;&#125; 存储地图点函数——SaveMapPoint()函数的实现： 123456789void Map::SaveMapPoint( ofstream&amp; f, MapPoint* mp)&#123; //Save ID and the x,y,z coordinates of the current MapPoint f.write((char*)&amp;mp-&gt;mnId, sizeof(mp-&gt;mnId)); cv::Mat mpWorldPos = mp-&gt;GetWorldPos(); f.write((char*)&amp; mpWorldPos.at&lt;float&gt;(0),sizeof(float)); f.write((char*)&amp; mpWorldPos.at&lt;float&gt;(1),sizeof(float)); f.write((char*)&amp; mpWorldPos.at&lt;float&gt;(2),sizeof(float));&#125; 存储关键帧函数——SaveKeyFrame()函数的实现： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263void Map::SaveKeyFrame( ofstream &amp;f, KeyFrame* kf )&#123; //Save the ID and timesteps of current KeyFrame f.write((char*)&amp;kf-&gt;mnId, sizeof(kf-&gt;mnId)); // cout &lt;&lt; "saving kf-&gt;mnId = " &lt;&lt; kf-&gt;mnId &lt;&lt;endl; f.write((char*)&amp;kf-&gt;mTimeStamp, sizeof(kf-&gt;mTimeStamp)); //Save the Pose Matrix of current KeyFrame cv::Mat Tcw = kf-&gt;GetPose(); ////Save the rotation matrix // for ( int i = 0; i &lt; Tcw.rows; i ++ ) // &#123; // for ( int j = 0; j &lt; Tcw.cols; j ++ ) // &#123; // f.write((char*)&amp;Tcw.at&lt;float&gt;(i,j), sizeof(float)); // //cerr&lt;&lt;"Tcw.at&lt;float&gt;("&lt;&lt;i&lt;&lt;","&lt;&lt;j&lt;&lt;"):"&lt;&lt;Tcw.at&lt;float&gt;(i,j)&lt;&lt;endl; // &#125; // &#125; //Save the rotation matrix in Quaternion std::vector&lt;float&gt; Quat = Converter::toQuaternion(Tcw); for ( int i = 0; i &lt; 4; i ++ ) f.write((char*)&amp;Quat[i],sizeof(float)); //Save the translation matrix for ( int i = 0; i &lt; 3; i ++ ) f.write((char*)&amp;Tcw.at&lt;float&gt;(i,3),sizeof(float)); //Save the size of the ORB features current KeyFrame //cerr&lt;&lt;"kf-&gt;N:"&lt;&lt;kf-&gt;N&lt;&lt;endl; f.write((char*)&amp;kf-&gt;N, sizeof(kf-&gt;N)); //Save each ORB features for( int i = 0; i &lt; kf-&gt;N; i ++ ) &#123; cv::KeyPoint kp = kf-&gt;mvKeys[i]; f.write((char*)&amp;kp.pt.x, sizeof(kp.pt.x)); f.write((char*)&amp;kp.pt.y, sizeof(kp.pt.y)); f.write((char*)&amp;kp.size, sizeof(kp.size)); f.write((char*)&amp;kp.angle,sizeof(kp.angle)); f.write((char*)&amp;kp.response, sizeof(kp.response)); f.write((char*)&amp;kp.octave, sizeof(kp.octave)); //Save the Descriptors of current ORB features f.write((char*)&amp;kf-&gt;mDescriptors.cols, sizeof(kf-&gt;mDescriptors.cols)); //kf-&gt;mDescriptors.cols is always 32 here. for (int j = 0; j &lt; kf-&gt;mDescriptors.cols; j ++ ) f.write((char*)&amp;kf-&gt;mDescriptors.at&lt;unsigned char&gt;(i,j), sizeof(char)); //Save the index of MapPoints that corresponds to current ORB features unsigned long int mnIdx; MapPoint* mp = kf-&gt;GetMapPoint(i); if (mp == NULL ) mnIdx = ULONG_MAX; else mnIdx = mmpnMapPointsIdx[mp]; f.write((char*)&amp;mnIdx, sizeof(mnIdx)); &#125; // Save BoW for relocalization. // f.write((char*)&amp;kf-&gt;mBowVec, sizeof(kf-&gt;mBowVec));&#125; GetMapPointsIdx()函数的实现过程为： 12345678910void Map::GetMapPointsIdx()&#123; unique_lock&lt;mutex&gt; lock(mMutexMap); unsigned long int i = 0; for ( auto mp: mspMapPoints ) &#123; mmpnMapPointsIdx[mp] = i; i += 1; &#125;&#125; （3）修改Converter相关文件关于旋转矩阵的存储可以通过四元数或矩阵的形式存储，如果使用四元数需要自定义一个矩阵和四元数相互转换的函数，在Converter.cc类里面添加如下函数： 123456789101112cv::Mat Converter::toCvMat(const std::vector&lt;float&gt;&amp; v)&#123; Eigen::Quaterniond q; q.x() = v[0]; q.y() = v[1]; q.z() = v[2]; q.w() = v[3]; Eigen::Matrix&lt;double,3,3&gt; eigMat(q); cv::Mat M = toCvMat(eigMat); return M;&#125; 在Converter.h里面加上如下函数定义 1static cv::Mat toCvMat( const std::vector&lt;float&gt;&amp; v )； （4）System文件修改上述修改完成之后，还需要对system.h和system.cc文件进行修改，分别添加声明和定义。system.h文件： 1void SaveMap(const string &amp;filename); system.cc文件: 12345//地图保存void System::SaveMap(const string &amp;filename)&#123; mpMap-&gt;Save(filename);&#125; 1.3 测试做完这些修改之后，在Examples文件中对应的示例程序中加入地图存储代码即可实现地图存储功能。 修改/ORB_SLAM2/Examples/ROS/ORB_SLAM2/src/ros_rgbd.cc文件中的main函数中加入如下语句： 1SLAM.SaveMap("map.bin"); 重新编译ORB_SLAM2库 123456789cd ~/ORB_SLAM2chmod +x build.sh./build.sh source /opt/ros/kinetic/setup.shsource ~/.bashrcchmod +x build_ros.sh./build_ros.sh### 若出错，参考 ORB_slam实现 测试 12345678roscore### 新建终端roslaunch kinect2_bridge kinect2_bridge.launch### 新建终端cd ~/ORB_SLAM2/Examples/ROS/ORB_SLAM2rosrun ORB_SLAM2 RGBD /home/zj224/ORB_SLAM2/Vocabulary/ORBvoc.txt /home/zj224/ORB_SLAM2/Examples/RGB-D/kinect2.yaml### 建图完成后 ctrl+C 地图保存在/ORB_SLAM2/Examples/ROS/ORB_SLAM2]]></content>
      <categories>
        <category>slam</category>
      </categories>
      <tags>
        <tag>slam实现</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[yilia 主题一些问题解决]]></title>
    <url>%2F2019%2F08%2F25%2Fyilia%20%E4%B8%BB%E9%A2%98%E4%B8%80%E4%BA%9B%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3%2F</url>
    <content type="text"><![CDATA[1 公式无法显示yilia 目录下有一个_config.yml 编辑里面的 123#数学公式mathjax: false 将false 改为true即可 2 修改头像yilia 目录下有一个_config.yml 编辑里面的 12#你的头像urlavatar: /img/1.jpg 将头像图片放在yilia/source/img中即可 3 上传图片配置 hexo 的_config.yml 1post_asset_folder: true 安装上传本地图片插件 1npm install hexo-asset-image --save ### 先cd 到你的文件夹 新建博客 12hexo n &quot;xxx&quot;# 在/source/_posts路径下会生成一个xxx.md和xxx文件 在md文件中引入图片，将你的图片放入xxx文件夹中 1![你想输入的替代文字](xxxx/图片名.jpg)]]></content>
      <categories>
        <category>问题解决</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ORB_SLAM2 在ROS中使用KinectV2实现]]></title>
    <url>%2F2019%2F08%2F24%2FORB_SLAM2%20%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[安装依赖包12345678910111213141516171819202122ssh -T git@github.comsudo apt-get install libboost-all-dev libblas-dev liblapack-dev#### 安装 Pangolingit clone git@github.com:stevenlovegrove/Pangolin.gitcd Pangolinmkdir buildcd buildcmake ..cmake --build .##### 安装 eigenhttp://eigen.tuxfamily.org/index.php?title=Main_Page ### 下载eigen包 解压cd eigenmkdir buildcd buildcmake ..makesudo make installsudo apt-get install libopencv-dev libeigen3-dev libqt4-dev qt4-qmake libqglviewer-dev libsuitesparse-dev libcxsparse3.1.4 libcholmod3.0.6 安装ORB_SLAM21234567891011git clone git@github.com:raulmur/ORB_SLAM2.gitcd ORB_SLAM2chmod +x build.shgedit ./build.sh修改最后一行，改为make./build.sh### 若报错 error: ‘usleep’ was not declaredcd ORB_SLAM2/srcgedit System.cc ### 报错的其他文件一样，不再一一说明，很多，要有耐心 T_T添加头文件 #include &lt;unistd.h&gt; 配置KINECT 苏齐光已经整理了一个Kinect配置文件，这里不再赘述。 KINECT 标定制作标定板chess5x7x0.03.pdfchess7x9x0.025.pdfchess9x11x0.02.pdf 这里我选择的是第三个 ！！！这里一定要注意，9x11实际上方格数是10x12 ！！！这里我搞错了耽误了一天。。。 建立临时文件夹以免图片太多看起来很乱 12mkdir ~/kinect_cal_tempcd kinect_cal_temp 标定步骤12345678910111213141516171819202122rosrun kinect2_bridge kinect2_bridge _fps_limit:=2 ### 先运行roscore### 显示的 [ INFO] [Kinect2Bridge::initDevice] device serial: 019968265047 后面的数为设备串口号### 在我的/home/catkin_ws/src/iai_kinect2/kinect2_bridge/data的文件夹里建立一个文件夹，取名叫 019968265047### 标定彩色摄像头：rosrun kinect2_calibration kinect2_calibration chess9x11x0.02 record color ### 按空格保存图片，10+张，后面一样rosrun kinect2_calibration kinect2_calibration chess9x11x0.02 calibrate color生成calib_color.yaml 文件 ### 标定红外rosrun kinect2_calibration kinect2_calibration chess9x11x0.02 record irrosrun kinect2_calibration kinect2_calibration chess9x11x0.02 calibrate ir### 会生成calib_ir.yaml 文件### 帧同步标定rosrun kinect2_calibration kinect2_calibration chess9x11x0.02 record syncrosrun kinect2_calibration kinect2_calibration chess9x11x0.02 calibrate sync### 会生成calib_pose.yaml 文件 ### 深度标定rosrun kinect2_calibration kinect2_calibration chess9x11x0.02 calibrate depth### 会生成calib_depth.yaml 文件 标定后的文件calib_color.yaml calib_ir.yaml calib_pose.yaml calib_depth.yaml 需要放到/home/catkin_ws/src/iai_kinect2/kinect2_bridge/data/019968265047这个文件夹里 标定至此完成！ 修改 ORB-SLAM2文件改动 1修改/home/zj224/ORB_SLAM2/Examples/ROS/ORB_SLAM2/src 中的 ros_rgbd.cc 文件的 main 函数： 12message_filters::Subscriber&lt;sensor_msgs::Image&gt; rgb_sub(nh, &quot;/camera/rgb/image_raw&quot;, 1);message_filters::Subscriber&lt;sensor_msgs::Image&gt; depth_sub(nh,&quot;camera/depth_registered/image_raw&quot;, 1); 改为： 12message_filters::Subscriber&lt;sensor_msgs::Image&gt; rgb_sub(nh,&quot;/kinect2/qhd/image_color&quot;,1);message_filters::Subscriber&lt;sensor_msgs::Image&gt; depth_sub(nh,&quot;/kinect2/qhd/image_depth_rect&quot;,1); 改动 2设置标定相机参数，仿照/Examples/RGB-D/TUM1.yaml 根据之前得到的 calib_color.yaml 修改并另存为 kinect2.yaml 1234567891011121314# Camera calibration and distortion parameters (OpenCV) Camera.fx: 1.0679837281443886e+03Camera.fy: 1.0697937777504162e+03Camera.cx: 9.3735357113460532e+02Camera.cy: 5.5068347235162321e+02Camera.k1: 8.4529458178805153e-02Camera.k2: -1.3472803452135898e-01Camera.p1: 2.4226930973738920e-03Camera.p2: -3.1065128414445530e-03Camera.k3: 3.3625687689377249e-03Camera.width: 1920Camera.height: 1080 改动 3123sudo gedit ~/.bashrc添加 export ROS_PACKAGE_PATH=$&#123;ROS_PACKAGE_PATH&#125;:/home/zj224/ORB_SLAM2/Examples/ROSsource ~/.bashrc 再次编译 ORB_SLAM2 12345678cd ~/ORB_SLAM2chmod +x build.sh./build.sh source /opt/ros/kinetic/setup.shchmod +x build_ros.sh./build_ros.sh 报错 [rosbuild] rospack found package “ORB_SLAM2” at “”, but the current directory is “/home/zj224/ORB_SLAM2/Examples/ROS/ORB_SLAM2”. 运行： 12sudo ln -s /home/ORB_SLAM2/Examples/ROS/ORB_SLAM2 /opt/ros/kinetic/share/ORB_SLAM2source ~/.bashrc 报错 CMakeFiles/RGBD.dir/src/ros_rgbd.cc.o: undefined reference to symbol ‘_ZN5boost6system15system_categoryEv’ 将/usr/lib/x86_64-linux-gnu/libboost_system.so/usr/lib/x86_64-linux-gnu/libboost_filesystem.so两个文件复制到 ORB_SLAM2 / lib修改/home/zj224/ORB_SLAM2/Examples/ROS/ORB_SLAM2 中的 CMakeLists.txt修改前： 123456789set(LIBS $&#123;OpenCV_LIBS&#125; $&#123;EIGEN3_LIBS&#125;$&#123;Pangolin_LIBRARIES&#125;$&#123;PROJECT_SOURCE_DIR&#125;/../../../Thirdparty/DBoW2/lib/libDBoW2.so$&#123;PROJECT_SOURCE_DIR&#125;/../../../Thirdparty/g2o/lib/libg2o.so$&#123;PROJECT_SOURCE_DIR&#125;/../../../lib/libORB_SLAM2.so) 修改后： 12345678910set(LIBS $&#123;OpenCV_LIBS&#125; $&#123;EIGEN3_LIBS&#125;$&#123;Pangolin_LIBRARIES&#125;$&#123;PROJECT_SOURCE_DIR&#125;/../../../Thirdparty/DBoW2/lib/libDBoW2.so$&#123;PROJECT_SOURCE_DIR&#125;/../../../Thirdparty/g2o/lib/libg2o.so$&#123;PROJECT_SOURCE_DIR&#125;/../../../lib/libORB_SLAM2.so-lboost_system) 运行程序1roscore 新建一个终端 1roslaunch kinect2_bridge kinect2_bridge.launch 新建一个终端 12cd ~/ORB_SLAM2/Examples/ROS/ORB_SLAM2rosrun ORB_SLAM2 RGBD /home/zj224/ORB_SLAM2/Vocabulary/ORBvoc.txt /home/zj224/ORB_SLAM2/Examples/RGB-D/kinect2.yaml]]></content>
      <categories>
        <category>slam</category>
      </categories>
      <tags>
        <tag>slam实现</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[回环检测]]></title>
    <url>%2F2019%2F08%2F22%2F%E5%9B%9E%E7%8E%AF%E6%A3%80%E6%B5%8B%2F</url>
    <content type="text"><![CDATA[1 什么是回环检测？ 在视觉slam问题中，位姿的估计往往是一个递推的过程，即由上一帧位姿解算当前帧位姿，因此其中的误差便这样一帧一帧的传递下去，也就是我们所说的累计误差。 我们的位姿约束都是与上一帧建立的，第五帧的位姿误差中便已经积累了前面四个约束中的误差。但如果我们发现第五帧位姿不一定要由第四帧推出来，还可以由第二帧推算出来，显然这样计算误差会小很多，因为只存在两个约束的误差了。像这样与之前的某一帧建立位姿约束关系就叫做回环。回环通过减少约束数，起到了减小累计误差的作用。 那么我们怎么知道可以由第二帧推算第五帧位姿呢？也许第一帧、第三帧也可以呢。确实，我们之所以用前一帧递推下一帧位姿，因为这两帧足够近，肯定可以建立两帧的约束，但是距离较远的两帧就不一定可以建立这样的约束关系了。找出可以建立这种位姿约束的历史帧，就是回环检测。 2 回环检测的意义 举例来说，假设我们在前端提取了特征，然后忽略掉特征点，在后端使用 Pose Graph优化整个轨迹，如图 12-1(a) 所示。由于前端给出的只是局部的位姿间约束，比方说，可能是$x_1 − x_2$， $x_ 2 − x _3 $等等。但是，由于 $x _1$ 的估计存在误差,而 $x_2 $是根据 $x _1$ 决定的,$x_3$是由$x_2 $决定的。以此类推，误差就会被累积起来，使得后端优化的结果如图 12-1 (b)所示，慢慢地趋向不准确。而回环检测则可以消除这种累积误差，如图12-1 (c)所示。 回环检测对于 SLAM 系统意义重大。它关系到我们估计的轨迹和地图在长时间下的正确性。另一方面，由于回环检测提供了当前数据与所有历史数据的关联，在跟踪算法丢失之后，我们还可以利用回环检测进行重定位。因此，回环检测对整个 SLAM 系统精度与鲁棒性的提升，是非常明显的。甚至在某些时候，我们把仅有前端和局部后端的系统称为VO，而把带有回环检测和全局后端的称为 SLAM。 3 回环检测的方法 回环的产生是因为相机经过了同一个地方，采集到了相似的数据。而回环检测的关键，就是如何有效地检测出相机经过同一个地方这件事。 回环检测的方法大致分为两种思路：基于里程计的几何关系(Odometry based)，或基于外观(Appearance based)。这里只讲最主流的基于外观的回环检测方法。 它和前端后端的估计都无关，仅根据两张图像的相似性确定回环检测关系。这种做法摆脱了累计误差，使回环检测模块成为 SLAM 系统中一个相对独立的模块（当然前端可以为它提供特征点）。 3.1 准确率和召回率(Precision &amp; Recall)$$Precision = TP/(TP+FP) , Recall = TP/(TP+FN)$$ 准确率描述的是，算法提取的所有回环中，确实是真实回环的概率。 召回率则是说，在所有真实回环中，被正确检测出来的概率。 在 SLAM 中，我们对准确率要求更高，而对召回率则相对宽容一些。 3.2 词袋模型 在基于外观的回环检测算法中，核心问题是如何计算图像间的相似性。 最为直观的想法就是直接对比两个图像的矩阵，将两个图像相减，但是由于灰度是一种不稳定的测量值，严重受环境光照和相机曝光的影响，此外如果相机视角发生少量变化，同样的物体，同样的光照，像素发生了位移就会导致灰度值产生巨大差异。 词袋，也就是 Bag-of-Words（BoW），目的是用”图像上有哪几种特征“来描述一个图像。例如，如果某个照片，我们说里面有一个人、一辆车；而另一张则有两个人、一只狗。根据这样的描述，可以度量这两个图像的相似性。 ”人、车、狗“就是单词（Word）；许多单词放在一起组成字典（dictionary）。 “人”、“车”、“狗”都是记录在字典中的单词，我们不妨记为 $w_1,w_2,w_3$ 。然后，对于任意图像 A，根据它们含有的单词，可记为: $A=1\times w_1+1\times w_2+0\times w_3$ （即，$[1,1,0]^T$）来表示图像A中有一个“人”，一辆“车”，没有“狗”。这种方式只考虑有没有，不考虑在哪儿，能保证相机发生少量运动时，描述向量不发生变化。 3.3 字典 按照前面的介绍，字典由很多单词组成，而每一个单词代表了一个概念。一个单词与一个单独的特征点不同，它不是从单个图像上提取出来的，而是某一类特征的组合。所以，字典生成问题类似于一个聚类(Clustering)问题。 聚类问题是无监督机器学习(Unsupervised ML)中一个特别常见的问题，而K-means 是一个非常简单有效的方法。当我们有 N 个数据，想要归成 k 个类，K-means的步骤为： 随机选取 k 个中心点：$c_1 , . . . , c_k $； 对每一个样本，计算与每个中心点之间的距离，取最小的作为它的归类； 重新计算每个类的中心点。 如果每个中心点都变化很小，则算法收敛，退出；否则返回 1。 考虑到字典的通用性 ，,我们通常会使用一个较大规模的字典。这就需要使用k叉树来表达字典了。假定我们有 N 个特征点，希望构建一个深度为 d，每次分叉为 k 的树，那么做法如下：（如图12-4） 在根节点，用 k-means 把所有样本聚成 k 类。这样得到了第一层。 对第一层的每个节点，把属于该节点的样本再聚成 k 类，得到下一层。 依此类推，最后得到叶子层。叶子层即为所谓的 Words。 3.4 相似度计算 当我们建立了字典，并对两个图片分析特征点得到他们的词袋后，如何计算它们的相似的便成为一个非常关键的问题。考虑到，不同的单词在区分性上的重要性并不相同。例如“的”、“是”这样的字可能在许许多多的句子中出现，我们无法根据它们判别句子的类型；但如果有“文档”、“足球”这样的单词，对判别句子的作用就更大一些，可以说它们提供了更多信息。所以概括的话，我们希望对单词的区分性或重要性加以评估，给它们不同的权值以起到更好的效果。 在文本检索中，常用的一种做法称为 TF-IDF（Term Frequency–Inverse Document Frequency）。TF 部分的思想是，某单词在一个图像中经常出现，它的区分度就高。另一方面，IDF 的思想是，某单词在字典中出现的频率越低，则分类图像时区分度越高。 我们统计某个叶子节点 $w_i$ 中的特征数量相对于所有特征数量的比例，作为 IDF 部分。假设所有特征数量为 $n$，$w_i $数量为$n_i$ ，那么该单词的 IDF 为：$IDF_i=log\frac{n}{n_i}$ 另一方面，TF 部分则是指某个特征在单个图像中出现的频率。假设图像 A 中，单词$w_i $出现了$n_i$ 次，而一共出现的单词次数为$n$，那么 TF 为：$TF_i=\frac{n_i}{n}$ 单词$w_i $的权重等于：$\eta_i=TF_i\times IDF_i$ 考虑权重以后，对于某个图像 A，它的特征点可对应到许多个单词，组成它的 Bag-of-Words: $$A=[(w_1,\eta_1),(w_2,\eta_2),\cdots,(w_N,\eta_N)]=v_A$$ 给定 $v_A$和 $v_B$计算差异：$s(v_A-v_B)=$$\sqrt{\sum_{i=1}^{N}{|v_{Ai}-v_{Bi}|^2}}$ 欧氏距离；余弦相似度。。。 相似性评分的处理 对于一些相识度本身就很高的场景，单纯的计算相识度、设置阈值是很难取得好的效果的。这时候需要相对相似度的评分处理。取一个先验相似度 $s(v_t,v_{t-\Delta t})$，它表示某时刻关键帧图像与上一时刻的关键帧的相似性。然后，其他的分值都参照这个值进行归一化:$s(v_t,v_{t_j})’=s(v_t,v_{t_j})/s(v_t,v_{t-\Delta t})$，再设置阈值。 4 回环检测的实现主要使用的库基础库：DBoW3 https://github.com/rmsalinas/DBow3 slam方法库：ORB_SLAM2 https://github.com/raulmur/ORB_SLAM2 改进参考： https://github.com/Ewenwan/ORB_SLAM2_SSD_Semantic 参考资料： https://www.cnblogs.com/slamtec/p/9837877.html 视觉slam十四讲_高翔]]></content>
      <categories>
        <category>slam</category>
      </categories>
      <tags>
        <tag>slam理论</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[激光雷达安装步骤]]></title>
    <url>%2F2019%2F08%2F21%2F%E6%BF%80%E5%85%89%E9%9B%B7%E8%BE%BE%E5%AE%89%E8%A3%85%E6%AD%A5%E9%AA%A4%2F</url>
    <content type="text"><![CDATA[1. 安装SDK1.1 下载相关文件 网址：http://go.slamtec.com/rplidar/a3/download 我已将相关文件下载至思岚雷达文件夹 后续工作可以按照我的说明，不必去看SDK说明，里面包含Windows、macos等安装，很杂。 1.2 编译SDK 解压SDK压缩包至根目录，重命名为rplidar_sdk cd ~/rplidar_sdk/sdk make 1.3 交叉编译 我没有进行这一步骤，因为目前不知道是否需要 透过交叉编译特性,SDK 的编译系统支持编译产生其他平台/系统的二进制可执行文件。注意: 该功能仅针对使用 Makefile 的环境.交叉编译特性将通过调用 cross_compile.sh 脚本激活。该脚本的调用语法如下:CROSS_COMPILE_PREFIX= ./cross_compile.sh例如: CROSS_COMPILE_PREFIX=arm-linux-gnueabihf ./cross_compile.sh 2. 连接雷达和PC 直接接电脑即可 3. 运行DEMO3.1 ultra_simple 该示例程序演示 PC 通过串口与 RPLIDAR 进行连接，并不断的将 RPLIDAR 扫描数据输出的最简单过程。 ls /dev/ttyUSB* ##这个命令可以检测你的雷达USB编号，看你雷达连上没 cd ~/rplidar_sdk/sdk/output/Linux/Release ./ultra_simple /dev/ttyUSB0 能转起来就说明安装好了]]></content>
      <categories>
        <category>slam</category>
      </categories>
      <tags>
        <tag>slam实现</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ubuntu系统备份为ISO文件]]></title>
    <url>%2F2019%2F08%2F21%2Fubuntu%E7%B3%BB%E7%BB%9F%E5%A4%87%E4%BB%BD%E4%B8%BAISO%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[1 安装systemback12345sudo add-apt-repository ppa:nemh/systembacksudo apt-get updatesudo apt-get install systemback unionfs-fuse 2 制作当前系统的镜像该软件还可以设置还原点，进行系统还原，操作很简单，一键设置一键还原，这里不再介绍 打开systemback 输入密码 选择Live system create 勾选 include the user data files 点击create new 生成备份结束后，选择备份文件，点击Convert to ISO 到你保存的路径下就能看到整体打包的系统ISO文件。 3 问题处理我进行完成2.5后，无法转为ISO文件，原因为系统大小大于4GB，解决办法如下： 创建sblive文件夹并解压通过systemback生成的.sblive 文件至sblive文件夹: 12mkdir sblivetar -xf /home/systemback_live_2019-08-16.sblive -C sblive ## 中间为你创建的镜像 重命名 syslinux 至 isolinux: 12mv sblive/syslinux/syslinux.cfg sblive/syslinux/isolinux.cfgmv sblive/syslinux sblive/isolinux 安装 cdtools 123456789101112sudo apt-get install aria2 aria2c -s 10 https://nchc.dl.sourceforge.net/project/cdrtools/alpha/cdrtools-3.02a07.tar.gz tar -xzvf cdrtools-3.02a07.tar.gz cd /home/hadoop/cdrtools-3.02 make sudo make install 生成 ISO 文件: 123cd ~ /opt/schily/bin/mkisofs -iso-level 3 -r -V sblive -cache-inodes -J -l -b isolinux/isolinux.bin -no-emul-boot -boot-load-size 4 -boot-info-table -c isolinux/boot.cat -o sblive.iso sblive 等待执行完成，我们便可在主文件夹下看见生成的sblive.iso镜像文件了 该部分来自：本文链接：https://blog.csdn.net/qq_39940390/article/details/94980229 4 系统安装1 虚拟机 VM14虚拟机的安装包和ubuntu16.04的ISO文件在实验室三星U盘里 安装过程可以参考 https://blog.csdn.net/qq_28090573/article/details/82724910，非常详细 我尝试了在虚拟机中安装我自己生成的ISO文件，但是卡在登陆界面无法进入，在网上查了很久尝试了很多方法也没能解决，最后选择了安装原生ubuntu的ISO文件 2 双系统未尝试安装 总结 systemback 的系统还原功能亲测可用，但是还原点会占一定的存储空间，建议只在重大环境安装前后备份使用 systemback 的ISO文件刻录功能亲测可用，但是得到的ISO文件在安装过程中存在问题，目前没有证明得到的ISO文件可以完成安装（虽然网上很多成功的。。。。）]]></content>
      <categories>
        <category>问题解决</category>
      </categories>
      <tags>
        <tag>Ubuntu系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[激光雷达和ROS结合]]></title>
    <url>%2F2019%2F08%2F21%2F%E6%BF%80%E5%85%89%E9%9B%B7%E8%BE%BE%E5%92%8CROS%E7%BB%93%E5%90%88%2F</url>
    <content type="text"><![CDATA[网址：https://github.com/slamtec/rplidar_ros 1 下载整个rplidar_ros包 cd catkin_ws/src ##到你的工作空间的src git clone https://github.com/Slamtec/rplidar_ros.git cd .. catkin_make source ./devel/setup.bash 2 运行rplidar_ros包###每次雷达重新连接电脑时，需要进行2.1前的步骤，如果USB口不是USB0，需要改动launch文件中的 param name=”serial_port” type=”string” value=”/dev/rplidar”/ ls -l /dev |grep ttyUSB #检查雷达的USB口 sudo chmod 666 /dev/ttyUSB0 #赋予权限 2.1在rviz中显示 roslaunch rplidar_ros view_rplidar_a3.launch 2.2在终端显示 roslaunch rplidar_ros rplidar_a3.launch #启动雷达 rosrun rplidar_ros rplidarNodeClient #在另外一个终端打开]]></content>
      <categories>
        <category>slam</category>
      </categories>
      <tags>
        <tag>slam实现</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[修改默认打开方式]]></title>
    <url>%2F2019%2F08%2F21%2F%E4%BF%AE%E6%94%B9%E9%BB%98%E8%AE%A4%E6%89%93%E5%BC%80%E6%96%B9%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[刚装上Typaro时markdown文件没有默认用它打开，而且打开方式中也找不到，可以采用以下方法 个人的打开方式保存在~/.local/share/applications/mimeapps.list 1sudo gedit ~/.local/share/applications/mimeapps.list 修改mimeapps.list 文件，在文件末尾添加 1text/markdown=typora.desktop 完成。]]></content>
      <categories>
        <category>问题解决</category>
      </categories>
      <tags>
        <tag>Ubuntu系统</tag>
      </tags>
  </entry>
</search>
