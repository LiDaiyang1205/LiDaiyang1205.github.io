<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[ORB_SLAM2地图保存与加载（1）]]></title>
    <url>%2F2019%2F08%2F26%2FORB_SLAM2%E5%9C%B0%E5%9B%BE%E4%BF%9D%E5%AD%98%E4%B8%8E%E5%8A%A0%E8%BD%BD%EF%BC%881%EF%BC%89%2F</url>
    <content type="text"><![CDATA[本文记录了ORB_SLAM2中地图保存的过程。参考博客：https://blog.csdn.net/qq_34254510/article/details/79969046http://www.cnblogs.com/mafuqiang/p/6972841.htmlhttps://blog.csdn.net/felaim/article/details/79667635https://blog.csdn.net/u014709760/article/details/86319090 1 地图保存1.1 地图元素分析所谓地图保存，就是保存地图“Map”中的各个元素，以及它们之间的关系，凡是跟踪过程中需要用到的东西自然也就是需要保存的对象。地图主要包含关键帧、3D地图点、BoW向量、共视图、生长树等，在跟踪过程中有三种跟踪模型和局部地图跟踪等过程，局部地图跟踪需要用到3D地图点、共视关系等元素，参考帧模型需要用到关键帧的BoW向量，重定位需要用到BoW向量、3D点等。所以基本上述元素都需要保存。 另一方面，关键帧也是一个抽象的概念（一个类），我们看看具体包含什么（其实都在关键帧类里面了），关键帧是从普通帧来的，所以得到视频帧后首先需要做的就是检测特征点，计算描述符，还有当前帧的相机位姿。成为关键帧之后需要有对应的ID编号，以及特征点进行三角化之后的3D地图点等。 关于3D地图点需要保存的就只有世界坐标了，至于其它的关联关系可以从关键帧获得。需要单独说的是在关键帧类中包含了特征点和描述符，所以BoW向量是不需要保存的（也没办法保存），只需要在加载了关键帧之后利用特征描述符重新计算即可。 所以现在需要保存的东西包括关键帧、3D地图点、共视图、生长树。 1.2 源码修改SLAM对地图维护的操作均在Map.cc这个函数类中，所以要保存地图，我们需要在这个文件中添加相应代码。 （1）修改Map.h头文件在/ORB_SLAM2/include/Map.h文件中的Map类中添加如下函数： 在Map.h的头文件中要添加Converter.h 123456789public: //保存地图信息 void Save(const string &amp;filename);protected: //保存地图点和关键帧 void SaveMapPoint(ofstream &amp;f,MapPoint* mp); void SaveKeyFrame(ofstream &amp;f,KeyFrame* kf); std::map&lt;MapPoint*, unsigned long int&gt; mmpnMapPointsIdx; void GetMapPointsIdx(); （2）修改Map.cc文件在/ORB_SLAM2/src/Map.cc文件中添加第一步中函数的实现。 Save()函数的实现过程： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162//保存地图信息void Map::Save ( const string&amp; filename )&#123; //Print the information of the saving map cerr&lt;&lt;"Map.cc :: Map Saving to "&lt;&lt;filename &lt;&lt;endl; ofstream f; f.open(filename.c_str(), ios_base::out|ios::binary); //Number of MapPoints unsigned long int nMapPoints = mspMapPoints.size(); f.write((char*)&amp;nMapPoints, sizeof(nMapPoints) ); //Save MapPoint sequentially for ( auto mp: mspMapPoints )&#123; //Save MapPoint SaveMapPoint( f, mp ); // cerr &lt;&lt; "Map.cc :: Saving map point number: " &lt;&lt; mp-&gt;mnId &lt;&lt; endl; &#125; //Print The number of MapPoints cerr &lt;&lt; "Map.cc :: The number of MapPoints is :"&lt;&lt;mspMapPoints.size()&lt;&lt;endl; //Grab the index of each MapPoint, count from 0, in which we initialized mmpnMapPointsIdx GetMapPointsIdx(); //Print the number of KeyFrames cerr &lt;&lt;"Map.cc :: The number of KeyFrames:"&lt;&lt;mspKeyFrames.size()&lt;&lt;endl; //Number of KeyFrames unsigned long int nKeyFrames = mspKeyFrames.size(); f.write((char*)&amp;nKeyFrames, sizeof(nKeyFrames)); //Save KeyFrames sequentially for ( auto kf: mspKeyFrames ) SaveKeyFrame( f, kf ); for (auto kf:mspKeyFrames ) &#123; //Get parent of current KeyFrame and save the ID of this parent KeyFrame* parent = kf-&gt;GetParent(); unsigned long int parent_id = ULONG_MAX; if ( parent ) parent_id = parent-&gt;mnId; f.write((char*)&amp;parent_id, sizeof(parent_id)); //Get the size of the Connected KeyFrames of the current KeyFrames //and then save the ID and weight of the Connected KeyFrames unsigned long int nb_con = kf-&gt;GetConnectedKeyFrames().size(); f.write((char*)&amp;nb_con, sizeof(nb_con)); for ( auto ckf: kf-&gt;GetConnectedKeyFrames()) &#123; int weight = kf-&gt;GetWeight(ckf); f.write((char*)&amp;ckf-&gt;mnId, sizeof(ckf-&gt;mnId)); f.write((char*)&amp;weight, sizeof(weight)); &#125; &#125; // Save last Frame ID // SaveFrameID(f); f.close(); cerr&lt;&lt;"Map.cc :: Map Saving Finished!"&lt;&lt;endl;&#125; 存储地图点函数——SaveMapPoint()函数的实现： 123456789void Map::SaveMapPoint( ofstream&amp; f, MapPoint* mp)&#123; //Save ID and the x,y,z coordinates of the current MapPoint f.write((char*)&amp;mp-&gt;mnId, sizeof(mp-&gt;mnId)); cv::Mat mpWorldPos = mp-&gt;GetWorldPos(); f.write((char*)&amp; mpWorldPos.at&lt;float&gt;(0),sizeof(float)); f.write((char*)&amp; mpWorldPos.at&lt;float&gt;(1),sizeof(float)); f.write((char*)&amp; mpWorldPos.at&lt;float&gt;(2),sizeof(float));&#125; 存储关键帧函数——SaveKeyFrame()函数的实现： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263void Map::SaveKeyFrame( ofstream &amp;f, KeyFrame* kf )&#123; //Save the ID and timesteps of current KeyFrame f.write((char*)&amp;kf-&gt;mnId, sizeof(kf-&gt;mnId)); // cout &lt;&lt; "saving kf-&gt;mnId = " &lt;&lt; kf-&gt;mnId &lt;&lt;endl; f.write((char*)&amp;kf-&gt;mTimeStamp, sizeof(kf-&gt;mTimeStamp)); //Save the Pose Matrix of current KeyFrame cv::Mat Tcw = kf-&gt;GetPose(); ////Save the rotation matrix // for ( int i = 0; i &lt; Tcw.rows; i ++ ) // &#123; // for ( int j = 0; j &lt; Tcw.cols; j ++ ) // &#123; // f.write((char*)&amp;Tcw.at&lt;float&gt;(i,j), sizeof(float)); // //cerr&lt;&lt;"Tcw.at&lt;float&gt;("&lt;&lt;i&lt;&lt;","&lt;&lt;j&lt;&lt;"):"&lt;&lt;Tcw.at&lt;float&gt;(i,j)&lt;&lt;endl; // &#125; // &#125; //Save the rotation matrix in Quaternion std::vector&lt;float&gt; Quat = Converter::toQuaternion(Tcw); for ( int i = 0; i &lt; 4; i ++ ) f.write((char*)&amp;Quat[i],sizeof(float)); //Save the translation matrix for ( int i = 0; i &lt; 3; i ++ ) f.write((char*)&amp;Tcw.at&lt;float&gt;(i,3),sizeof(float)); //Save the size of the ORB features current KeyFrame //cerr&lt;&lt;"kf-&gt;N:"&lt;&lt;kf-&gt;N&lt;&lt;endl; f.write((char*)&amp;kf-&gt;N, sizeof(kf-&gt;N)); //Save each ORB features for( int i = 0; i &lt; kf-&gt;N; i ++ ) &#123; cv::KeyPoint kp = kf-&gt;mvKeys[i]; f.write((char*)&amp;kp.pt.x, sizeof(kp.pt.x)); f.write((char*)&amp;kp.pt.y, sizeof(kp.pt.y)); f.write((char*)&amp;kp.size, sizeof(kp.size)); f.write((char*)&amp;kp.angle,sizeof(kp.angle)); f.write((char*)&amp;kp.response, sizeof(kp.response)); f.write((char*)&amp;kp.octave, sizeof(kp.octave)); //Save the Descriptors of current ORB features f.write((char*)&amp;kf-&gt;mDescriptors.cols, sizeof(kf-&gt;mDescriptors.cols)); //kf-&gt;mDescriptors.cols is always 32 here. for (int j = 0; j &lt; kf-&gt;mDescriptors.cols; j ++ ) f.write((char*)&amp;kf-&gt;mDescriptors.at&lt;unsigned char&gt;(i,j), sizeof(char)); //Save the index of MapPoints that corresponds to current ORB features unsigned long int mnIdx; MapPoint* mp = kf-&gt;GetMapPoint(i); if (mp == NULL ) mnIdx = ULONG_MAX; else mnIdx = mmpnMapPointsIdx[mp]; f.write((char*)&amp;mnIdx, sizeof(mnIdx)); &#125; // Save BoW for relocalization. // f.write((char*)&amp;kf-&gt;mBowVec, sizeof(kf-&gt;mBowVec));&#125; GetMapPointsIdx()函数的实现过程为： 12345678910void Map::GetMapPointsIdx()&#123; unique_lock&lt;mutex&gt; lock(mMutexMap); unsigned long int i = 0; for ( auto mp: mspMapPoints ) &#123; mmpnMapPointsIdx[mp] = i; i += 1; &#125;&#125; （3）修改Converter相关文件关于旋转矩阵的存储可以通过四元数或矩阵的形式存储，如果使用四元数需要自定义一个矩阵和四元数相互转换的函数，在Converter.cc类里面添加如下函数： 123456789101112cv::Mat Converter::toCvMat(const std::vector&lt;float&gt;&amp; v)&#123; Eigen::Quaterniond q; q.x() = v[0]; q.y() = v[1]; q.z() = v[2]; q.w() = v[3]; Eigen::Matrix&lt;double,3,3&gt; eigMat(q); cv::Mat M = toCvMat(eigMat); return M;&#125; 在Converter.h里面加上如下函数定义 1static cv::Mat toCvMat( const std::vector&lt;float&gt;&amp; v )； （4）System文件修改上述修改完成之后，还需要对system.h和system.cc文件进行修改，分别添加声明和定义。system.h文件： 1void SaveMap(const string &amp;filename); system.cc文件: 12345//地图保存void System::SaveMap(const string &amp;filename)&#123; mpMap-&gt;Save(filename);&#125; 1.3 测试做完这些修改之后，在Examples文件中对应的示例程序中加入地图存储代码即可实现地图存储功能。如在ORB_SLAM2/Examples/RGB-D/rgbd_tum.cc文件的main函数中加入如下语句： 1SLAM.SaveMap("map.bin"); 修改/ORB_SLAM2/Examples/ROS/ORB_SLAM2/src/ros_rgbd.cc文件中的main函数中加入如下语句： ### 实际上我们运行的是这个cc文件，上面那个可能改不改都行。。 1SLAM.SaveMap("map.bin"); 重新编译ORB_SLAM2库 123456789cd ~/ORB_SLAM2chmod +x build.sh./build.sh source /opt/ros/kinetic/setup.shsource ~/.bashrcchmod +x build_ros.sh./build_ros.sh### 若出错，参考 ORB_slam实现 测试 12345678roscore### 新建终端roslaunch kinect2_bridge kinect2_bridge.launch### 新建终端cd ~/ORB_SLAM2/Examples/ROS/ORB_SLAM2rosrun ORB_SLAM2 RGBD /home/zj224/ORB_SLAM2/Vocabulary/ORBvoc.txt /home/zj224/ORB_SLAM2/Examples/RGB-D/kinect2.yaml### 建图完成后 ctrl+C 地图保存在/ORB_SLAM2/Examples/ROS/ORB_SLAM2]]></content>
      <categories>
        <category>slam</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[yilia 主题一些问题解决]]></title>
    <url>%2F2019%2F08%2F25%2Fyilia%20%E4%B8%BB%E9%A2%98%E4%B8%80%E4%BA%9B%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3%2F</url>
    <content type="text"><![CDATA[1 公式无法显示yilia 目录下有一个_config.yml 编辑里面的 123#数学公式mathjax: false 将false 改为true即可 2 修改头像yilia 目录下有一个_config.yml 编辑里面的 12#你的头像urlavatar: /img/1.jpg 将头像图片放在yilia/source/img中即可 3 上传图片配置 hexo 的_config.yml 1post_asset_folder: true 安装上传本地图片插件 1npm install hexo-asset-image --save ### 先cd 到你的文件夹 新建博客 12hexo n &quot;xxx&quot;# 在/source/_posts路径下会生成一个xxx.md和xxx文件 在md文件中引入图片，将你的图片放入xxx文件夹中 1![你想输入的替代文字](xxxx/图片名.jpg)]]></content>
      <categories>
        <category>ubuntu问题</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ORB_SLAM2 在ROS中使用KinectV2实现]]></title>
    <url>%2F2019%2F08%2F24%2FORB_SLAM2%20%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[安装依赖包12345678910111213141516171819202122ssh -T git@github.comsudo apt-get install libboost-all-dev libblas-dev liblapack-dev#### 安装 Pangolingit clone git@github.com:stevenlovegrove/Pangolin.gitcd Pangolinmkdir buildcd buildcmake ..cmake --build .##### 安装 eigenhttp://eigen.tuxfamily.org/index.php?title=Main_Page ### 下载eigen包 解压cd eigenmkdir buildcd buildcmake ..makesudo make installsudo apt-get install libopencv-dev libeigen3-dev libqt4-dev qt4-qmake libqglviewer-dev libsuitesparse-dev libcxsparse3.1.4 libcholmod3.0.6 安装ORB_SLAM21234567891011git clone git@github.com:raulmur/ORB_SLAM2.gitcd ORB_SLAM2chmod +x build.shgedit ./build.sh修改最后一行，改为make./build.sh### 若报错 error: ‘usleep’ was not declaredcd ORB_SLAM2/srcgedit System.cc ### 报错的其他文件一样，不再一一说明，很多，要有耐心 T_T添加头文件 #include &lt;unistd.h&gt; 配置KINECT 苏齐光已经整理了一个Kinect配置文件，这里不再赘述。 KINECT 标定制作标定板chess5x7x0.03.pdfchess7x9x0.025.pdfchess9x11x0.02.pdf 这里我选择的是第三个 ！！！这里一定要注意，9x11实际上方格数是10x12 ！！！这里我搞错了耽误了一天。。。 建立临时文件夹以免图片太多看起来很乱 12mkdir ~/kinect_cal_tempcd kinect_cal_temp 标定步骤12345678910111213141516171819202122rosrun kinect2_bridge kinect2_bridge _fps_limit:=2 ### 先运行roscore### 显示的 [ INFO] [Kinect2Bridge::initDevice] device serial: 019968265047 后面的数为设备串口号### 在我的/home/catkin_ws/src/iai_kinect2/kinect2_bridge/data的文件夹里建立一个文件夹，取名叫 019968265047### 标定彩色摄像头：rosrun kinect2_calibration kinect2_calibration chess9x11x0.02 record color ### 按空格保存图片，10+张，后面一样rosrun kinect2_calibration kinect2_calibration chess9x11x0.02 calibrate color生成calib_color.yaml 文件 ### 标定红外rosrun kinect2_calibration kinect2_calibration chess9x11x0.02 record irrosrun kinect2_calibration kinect2_calibration chess9x11x0.02 calibrate ir### 会生成calib_ir.yaml 文件### 帧同步标定rosrun kinect2_calibration kinect2_calibration chess9x11x0.02 record syncrosrun kinect2_calibration kinect2_calibration chess9x11x0.02 calibrate sync### 会生成calib_pose.yaml 文件 ### 深度标定rosrun kinect2_calibration kinect2_calibration chess9x11x0.02 calibrate depth### 会生成calib_depth.yaml 文件 标定后的文件calib_color.yaml calib_ir.yaml calib_pose.yaml calib_depth.yaml 需要放到/home/catkin_ws/src/iai_kinect2/kinect2_bridge/data/019968265047这个文件夹里 标定至此完成！ 修改 ORB-SLAM2文件改动 1修改/home/zj224/ORB_SLAM2/Examples/ROS/ORB_SLAM2/src 中的 ros_rgbd.cc 文件的 main 函数： 12message_filters::Subscriber&lt;sensor_msgs::Image&gt; rgb_sub(nh, &quot;/camera/rgb/image_raw&quot;, 1);message_filters::Subscriber&lt;sensor_msgs::Image&gt; depth_sub(nh,&quot;camera/depth_registered/image_raw&quot;, 1); 改为： 12message_filters::Subscriber&lt;sensor_msgs::Image&gt; rgb_sub(nh,&quot;/kinect2/qhd/image_color&quot;,1);message_filters::Subscriber&lt;sensor_msgs::Image&gt; depth_sub(nh,&quot;/kinect2/qhd/image_depth_rect&quot;,1); 改动 2设置标定相机参数，仿照/Examples/RGB-D/TUM1.yaml 根据之前得到的 calib_color.yaml 修改并另存为 kinect2.yaml 1234567891011121314# Camera calibration and distortion parameters (OpenCV) Camera.fx: 1.0679837281443886e+03Camera.fy: 1.0697937777504162e+03Camera.cx: 9.3735357113460532e+02Camera.cy: 5.5068347235162321e+02Camera.k1: 8.4529458178805153e-02Camera.k2: -1.3472803452135898e-01Camera.p1: 2.4226930973738920e-03Camera.p2: -3.1065128414445530e-03Camera.k3: 3.3625687689377249e-03Camera.width: 1920Camera.height: 1080 改动 3123sudo gedit ~/.bashrc添加 export ROS_PACKAGE_PATH=$&#123;ROS_PACKAGE_PATH&#125;:/home/zj224/ORB_SLAM2/Examples/ROSsource ~/.bashrc 再次编译 ORB_SLAM2 12345678cd ~/ORB_SLAM2chmod +x build.sh./build.sh source /opt/ros/kinetic/setup.shchmod +x build_ros.sh./build_ros.sh 报错 [rosbuild] rospack found package “ORB_SLAM2” at “”, but the current directory is “/home/zj224/ORB_SLAM2/Examples/ROS/ORB_SLAM2”. 运行： 12sudo ln -s /home/ORB_SLAM2/Examples/ROS/ORB_SLAM2 /opt/ros/kinetic/share/ORB_SLAM2source ~/.bashrc 报错 CMakeFiles/RGBD.dir/src/ros_rgbd.cc.o: undefined reference to symbol ‘_ZN5boost6system15system_categoryEv’ 将/usr/lib/x86_64-linux-gnu/libboost_system.so/usr/lib/x86_64-linux-gnu/libboost_filesystem.so两个文件复制到 ORB_SLAM2 / lib修改/home/zj224/ORB_SLAM2/Examples/ROS/ORB_SLAM2 中的 CMakeLists.txt修改前： 123456789set(LIBS $&#123;OpenCV_LIBS&#125; $&#123;EIGEN3_LIBS&#125;$&#123;Pangolin_LIBRARIES&#125;$&#123;PROJECT_SOURCE_DIR&#125;/../../../Thirdparty/DBoW2/lib/libDBoW2.so$&#123;PROJECT_SOURCE_DIR&#125;/../../../Thirdparty/g2o/lib/libg2o.so$&#123;PROJECT_SOURCE_DIR&#125;/../../../lib/libORB_SLAM2.so) 修改后： 12345678910set(LIBS $&#123;OpenCV_LIBS&#125; $&#123;EIGEN3_LIBS&#125;$&#123;Pangolin_LIBRARIES&#125;$&#123;PROJECT_SOURCE_DIR&#125;/../../../Thirdparty/DBoW2/lib/libDBoW2.so$&#123;PROJECT_SOURCE_DIR&#125;/../../../Thirdparty/g2o/lib/libg2o.so$&#123;PROJECT_SOURCE_DIR&#125;/../../../lib/libORB_SLAM2.so-lboost_system) 运行程序1roscore 新建一个终端 1roslaunch kinect2_bridge kinect2_bridge.launch 新建一个终端 12cd ~/ORB_SLAM2/Examples/ROS/ORB_SLAM2rosrun ORB_SLAM2 RGBD /home/zj224/ORB_SLAM2/Vocabulary/ORBvoc.txt /home/zj224/ORB_SLAM2/Examples/RGB-D/kinect2.yaml]]></content>
      <categories>
        <category>slam</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[回环检测]]></title>
    <url>%2F2019%2F08%2F22%2F%E5%9B%9E%E7%8E%AF%E6%A3%80%E6%B5%8B%2F</url>
    <content type="text"><![CDATA[1 什么是回环检测？ 在视觉slam问题中，位姿的估计往往是一个递推的过程，即由上一帧位姿解算当前帧位姿，因此其中的误差便这样一帧一帧的传递下去，也就是我们所说的累计误差。 我们的位姿约束都是与上一帧建立的，第五帧的位姿误差中便已经积累了前面四个约束中的误差。但如果我们发现第五帧位姿不一定要由第四帧推出来，还可以由第二帧推算出来，显然这样计算误差会小很多，因为只存在两个约束的误差了。像这样与之前的某一帧建立位姿约束关系就叫做回环。回环通过减少约束数，起到了减小累计误差的作用。 那么我们怎么知道可以由第二帧推算第五帧位姿呢？也许第一帧、第三帧也可以呢。确实，我们之所以用前一帧递推下一帧位姿，因为这两帧足够近，肯定可以建立两帧的约束，但是距离较远的两帧就不一定可以建立这样的约束关系了。找出可以建立这种位姿约束的历史帧，就是回环检测。 2 回环检测的意义 举例来说，假设我们在前端提取了特征，然后忽略掉特征点,在后端使用 Pose Graph优化整个轨迹，如图 12-1(a) 所示。由于前端给出的只是局部的位姿间约束，比方说，可能是$x_1 − x_2$， $x_ 2 − x _3 $等等。但是，由于 $x _1$ 的估计存在误差,而 $x_2 $是根据 $x _1$ 决定的,$x_3$是由$x_2 $决定的。以此类推，误差就会被累积起来，使得后端优化的结果如图 12-1 (b)所示，慢慢地趋向不准确。而回环检测则可以消除这种累积误差，如图12-1 (c)所示。 回环检测对于 SLAM 系统意义重大。它关系到我们估计的轨迹和地图在长时间下的正确性。另一方面，由于回环检测提供了当前数据与所有历史数据的关联，在跟踪算法丢失之后，我们还可以利用回环检测进行重定位。因此，回环检测对整个 SLAM 系统精度与鲁棒性的提升，是非常明显的。甚至在某些时候，我们把仅有前端和局部后端的系统称为VO，而把带有回环检测和全局后端的称为 SLAM。 3 回环检测的方法 回环检测的方法有很多种。因为大多方法实现效果很差，这里只讲最主流的基于外观的回环检测方法。 它和前端后端的估计都无关，仅根据两张图像的相似性确定回环检测关系。这种做法摆脱了累计误差，使回环检测模块成为 SLAM 系统中一个相对独立的模块（当然前端可以为它提供特征点）。 3.1 准确率和召回率(Precision &amp; Recall)$$Precision = TP/(TP+FP) , Recall = TP/(TP+FN)$$ 准确率描述的是，算法提取的所有回环中，确实是真实回环的概率。 召回率则是说，在所有真实回环中，被正确检测出来的概率。 在 SLAM 中，我们对准确率要求更高，而对召回率则相对宽容一些。 3.2 词袋模型 在基于外观的回环检测算法中，核心问题是如何计算图像间的相似性。 最为直观的想法就是直接对比两个图像的矩阵，将两个图像相减，但是由于灰度是一种不稳定的测量值，严重受环境光照和相机曝光的影响，此外如果相机视角发生少量变化，同样的物体，同样的光照，像素发生了位移就会导致灰度值产生巨大差异。 词袋，也就是 Bag-of-Words（BoW），目的是用”图像上有哪几种特征“来描述一个图像。例如，如果某个照片，我们说里面有一个人、一辆车；而另一张则有两个人、一只狗。根据这样的描述，可以度量这两个图像的相似性。 ”人、车、狗“就是单词（Word）；许多单词放在一起组成字典（dictionary）。 “人”、“车”、“狗”都是记录在字典中的单词，我们不妨记为 $w_1,w_2,w_3$ 。然后,对于任意图像 A，根据它们含有的单词，可记为: $A=1\times w_1+1\times w_2+0\times w_3$ （即，$[1,1,0]^T$）来表示图像A中有一个“人”，一辆“车”，没有“狗”。这种方式只考虑有没有，不考虑在哪儿，能保证相机发生少量运动时，描述向量不发生变化。 3.3 字典 按照前面的介绍，字典由很多单词组成，而每一个单词代表了一个概念。一个单词与一个单独的特征点不同，它不是从单个图像上提取出来的，而是某一类特征的组合。所以，字典生成问题类似于一个聚类(Clustering)问题。 聚类问题是无监督机器学习(Unsupervised ML)中一个特别常见的问题，而K-means 是一个非常简单有效的方法。当我们有 N 个数据，想要归成 k 个类，K-means的步骤为： 随机选取 k 个中心点：$c_1 , . . . , c_k $； 对每一个样本，计算与每个中心点之间的距离，取最小的作为它的归类； 重新计算每个类的中心点。 如果每个中心点都变化很小，则算法收敛，退出；否则返回 1。 考虑到字典的通用性 ，,我们通常会使用一个较大规模的字典。这就需要使用k叉树来表达字典了。假定我们有 N 个特征点，希望构建一个深度为 d，每次分叉为 k 的树，那么做法如下：（如图12-4） 在根节点，用 k-means 把所有样本聚成 k 类。这样得到了第一层。 对第一层的每个节点，把属于该节点的样本再聚成 k 类，得到下一层。 依此类推，最后得到叶子层。叶子层即为所谓的 Words。 3.4 相似度计算 当我们建立了字典，并对两个图片分析特征点得到他们的词袋后，如何计算它们的相似的便成为一个非常关键的问题。考虑到，不同的单词在区分性上的重要性并不相同。例如“的”、“是”这样的字可能在许许多多的句子中出现，我们无法根据它们判别句子的类型；但如果有“文档”、“足球”这样的单词，对判别句子的作用就更大一些，可以说它们提供了更多信息。所以概括的话，我们希望对单词的区分性或重要性加以评估，给它们不同的权值以起到更好的效果。 在文本检索中，常用的一种做法称为 TF-IDF（Term Frequency–Inverse Document Frequency）。TF 部分的思想是，某单词在一个图像中经常出现，它的区分度就高。另一方面，IDF 的思想是，某单词在字典中出现的频率越低，则分类图像时区分度越高。 我们统计某个叶子节点 $w_i$ 中的特征数量相对于所有特征数量的比例，作为 IDF 部分。假设所有特征数量为 $n$，$w_i $数量为$n_i$ ，那么该单词的 IDF 为：$IDF_i=log\frac{n}{n_i}$ 另一方面，TF 部分则是指某个特征在单个图像中出现的频率。假设图像 A 中，单词$w_i $出现了$n_i$ 次，而一共出现的单词次数为$n$，那么 TF 为：$TF_i=\frac{n_i}{n}$ 单词$w_i $的权重等于：$\eta_i=TF_i\times IDF_i$ 考虑权重以后，对于某个图像 A，它的特征点可对应到许多个单词，组成它的 Bag-of-Words: $$A=[(w_1,\eta_1),(w_2,\eta_2),\cdots,(w_N,\eta_N)]=v_A$$ 给定 $v_A$和 $v_B$计算差异：$s(v_A-v_B)=2\sum_{i=1}^{N}{|v_{Ai}|+|v_{Bi}|-|v_{Ai}-v_{Bi}|}$ 4 回环检测的实现主要使用的库基础库：DBoW3 https://github.com/rmsalinas/DBow3 slam方法库：ORB_SLAM2 https://github.com/raulmur/ORB_SLAM2 改进参考： https://github.com/Ewenwan/ORB_SLAM2_SSD_Semantic 参考资料： https://www.cnblogs.com/slamtec/p/9837877.html 视觉slam十四讲_高翔]]></content>
      <categories>
        <category>slam</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ubuntu系统备份为ISO文件]]></title>
    <url>%2F2019%2F08%2F21%2Fubuntu%E7%B3%BB%E7%BB%9F%E5%A4%87%E4%BB%BD%E4%B8%BAISO%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[1 安装systemback12345sudo add-apt-repository ppa:nemh/systembacksudo apt-get updatesudo apt-get install systemback unionfs-fuse 2 制作当前系统的镜像该软件还可以设置还原点，进行系统还原，操作很简单，一键设置一键还原，这里不再介绍 打开systemback 输入密码 选择Live system create 勾选 include the user data files 点击create new 生成备份结束后，选择备份文件，点击Convert to ISO 到你保存的路径下就能看到整体打包的系统ISO文件。 3 问题处理我进行完成2.5后，无法转为ISO文件，原因为系统大小大于4GB，解决办法如下： 创建sblive文件夹并解压通过systemback生成的.sblive 文件至sblive文件夹: 12mkdir sblivetar -xf /home/systemback_live_2019-08-16.sblive -C sblive ## 中间为你创建的镜像 重命名 syslinux 至 isolinux: 12mv sblive/syslinux/syslinux.cfg sblive/syslinux/isolinux.cfgmv sblive/syslinux sblive/isolinux 安装 cdtools 123456789101112sudo apt-get install aria2 aria2c -s 10 https://nchc.dl.sourceforge.net/project/cdrtools/alpha/cdrtools-3.02a07.tar.gz tar -xzvf cdrtools-3.02a07.tar.gz cd /home/hadoop/cdrtools-3.02 make sudo make install 生成 ISO 文件: 123cd ~ /opt/schily/bin/mkisofs -iso-level 3 -r -V sblive -cache-inodes -J -l -b isolinux/isolinux.bin -no-emul-boot -boot-load-size 4 -boot-info-table -c isolinux/boot.cat -o sblive.iso sblive 等待执行完成，我们便可在主文件夹下看见生成的sblive.iso镜像文件了 该部分来自：本文链接：https://blog.csdn.net/qq_39940390/article/details/94980229 4 系统安装1 虚拟机 VM14虚拟机的安装包和ubuntu16.04的ISO文件在实验室三星U盘里 安装过程可以参考 https://blog.csdn.net/qq_28090573/article/details/82724910，非常详细 我尝试了在虚拟机中安装我自己生成的ISO文件，但是卡在登陆界面无法进入，在网上查了很久尝试了很多方法也没能解决，最后选择了安装原生ubuntu的ISO文件 2 双系统未尝试安装 总结 systemback 的系统还原功能亲测可用，但是还原点会占一定的存储空间，建议只在重大环境安装前后备份使用 systemback 的ISO文件刻录功能亲测可用，但是得到的ISO文件在安装过程中存在问题，目前没有证明得到的ISO文件可以完成安装（虽然网上很多成功的。。。。）]]></content>
      <categories>
        <category>ubuntu问题</category>
      </categories>
      <tags>
        <tag>系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[修改默认打开方式]]></title>
    <url>%2F2019%2F08%2F21%2F%E4%BF%AE%E6%94%B9%E9%BB%98%E8%AE%A4%E6%89%93%E5%BC%80%E6%96%B9%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[刚装上Typaro时markdown文件没有默认用它打开，而且打开方式中也找不到，可以采用以下方法 个人的打开方式保存在~/.local/share/applications/mimeapps.list 1sudo gedit ~/.local/share/applications/mimeapps.list 修改mimeapps.list 文件，在文件末尾添加 1text/markdown=typora.desktop 完成。]]></content>
      <categories>
        <category>ubuntu问题</category>
      </categories>
      <tags>
        <tag>系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[激光雷达和ROS结合]]></title>
    <url>%2F2019%2F08%2F21%2F%E6%BF%80%E5%85%89%E9%9B%B7%E8%BE%BE%E5%92%8CROS%E7%BB%93%E5%90%88%2F</url>
    <content type="text"><![CDATA[网址：https://github.com/slamtec/rplidar_ros 1 下载整个rplidar_ros包 cd catkin_ws/src ##到你的工作空间的src git clone https://github.com/Slamtec/rplidar_ros.git cd .. catkin_make source ./devel/setup.bash 2 运行rplidar_ros包###每次雷达重新连接电脑时，需要进行2.1前的步骤，如果USB口不是USB0，需要改动launch文件中的 param name=”serial_port” type=”string” value=”/dev/rplidar”/ ls -l /dev |grep ttyUSB #检查雷达的USB口 sudo chmod 666 /dev/ttyUSB0 #赋予权限 2.1在rviz中显示 roslaunch rplidar_ros view_rplidar_a3.launch 2.2在终端显示 roslaunch rplidar_ros rplidar_a3.launch #启动雷达 rosrun rplidar_ros rplidarNodeClient #在另外一个终端打开]]></content>
      <categories>
        <category>slam</category>
      </categories>
      <tags>
        <tag>硬件</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[激光雷达安装步骤]]></title>
    <url>%2F2019%2F08%2F21%2F%E6%BF%80%E5%85%89%E9%9B%B7%E8%BE%BE%E5%AE%89%E8%A3%85%E6%AD%A5%E9%AA%A4%2F</url>
    <content type="text"><![CDATA[1. 安装SDK1.1 下载相关文件 网址：http://go.slamtec.com/rplidar/a3/download 我已将相关文件下载至思岚雷达文件夹 后续工作可以按照我的说明，不必去看SDK说明，里面包含Windows、macos等安装，很杂。 1.2 编译SDK 解压SDK压缩包至根目录，重命名为rplidar_sdk cd ~/rplidar_sdk/sdk make 1.3 交叉编译 我没有进行这一步骤，因为目前不知道是否需要 透过交叉编译特性,SDK 的编译系统支持编译产生其他平台/系统的二进制可执行文件。注意: 该功能仅针对使用 Makefile 的环境.交叉编译特性将通过调用 cross_compile.sh 脚本激活。该脚本的调用语法如下:CROSS_COMPILE_PREFIX= ./cross_compile.sh例如: CROSS_COMPILE_PREFIX=arm-linux-gnueabihf ./cross_compile.sh 2. 连接雷达和PC 直接接电脑即可 3. 运行DEMO3.1 ultra_simple 该示例程序演示 PC 通过串口与 RPLIDAR 进行连接，并不断的将 RPLIDAR 扫描数据输出的最简单过程。 ls /dev/ttyUSB* ##这个命令可以检测你的雷达USB编号，看你雷达连上没 cd ~/rplidar_sdk/sdk/output/Linux/Release ./ultra_simple /dev/ttyUSB0 能转起来就说明安装好了]]></content>
      <categories>
        <category>slam</category>
      </categories>
      <tags>
        <tag>硬件</tag>
      </tags>
  </entry>
</search>
